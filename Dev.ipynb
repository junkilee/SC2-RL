{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial parameters sampling\n",
    "\n",
    "Take as input a batch of matrices of logits (B, L, L), where L is the linear size of the map.\n",
    "Returns [[x_1,y_1],...,[x_B, y_B]] (or [y,x]) integer coordinates of the sampled pixels, toghether with their log probs (shape (B,)) and the probs of all the pixels (shape (B,L^2)).\n",
    "Note: Softmax is performed inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_version(x, L, x_first=True, debug=True):\n",
    "    B = x.shape[0]\n",
    "    ### usually self.size instead of size and it is already known\n",
    "    size = L\n",
    "    ###\n",
    "    if debug: print(\"x.shape: \", x.shape)\n",
    "    x = x.reshape((x.shape[0],-1))\n",
    "    if debug: print(\"x.shape: \", x.shape)\n",
    "    log_probs = F.log_softmax(x, dim=(-1))\n",
    "    probs = torch.exp(log_probs)\n",
    "    if debug: \n",
    "        print(\"log_probs.shape: \", log_probs.shape)\n",
    "        print(\"log_probs.shape (reshaped): \", log_probs.view(-1, size, size).shape)\n",
    "\n",
    "    # assume squared space\n",
    "    x_lin = torch.arange(size).unsqueeze(0)\n",
    "    xx = x_lin.repeat(B,size,1)\n",
    "    if debug: print(\"xx.shape: \", xx.shape)\n",
    "    # yx \n",
    "    args = torch.cat([xx.view(-1,size,size,1), xx.permute(0,2,1).view(-1,size,size,1)], axis=3)\n",
    "    if debug: print(\"args.shape (before reshaping): \", args.shape)\n",
    "    args = args.reshape(B,-1,2)\n",
    "    if debug: print(\"args.shape (after reshaping): \", args.shape)\n",
    "    #print(\"args (after reshape): \", args)\n",
    "    index = Categorical(probs).sample()\n",
    "    arg = args[torch.arange(B), index].detach().numpy() # and this are the sampled coordinates\n",
    "    #print(\"index: \", index) \n",
    "    arg_lst = [list(a)  for a in arg] # swap to xy\n",
    "    #print(\"arg_lst: \", arg_lst)\n",
    "    log_probs = log_probs.reshape(B, size, size)\n",
    "    # CORRECT\n",
    "    return arg_lst, log_probs[torch.arange(B), arg[:,1], arg[:,0]], probs \n",
    "    # WRONG\n",
    "    # return arg_lst, log_probs[torch.arange(B), arg[:,0], arg[:,1]], probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def working_version(x, L, x_first=True, debug=True):\n",
    "    ### usually self.size instead of size and it is already known\n",
    "    size = L\n",
    "    ###\n",
    "    B = x.shape[0]\n",
    "    if debug: print(\"x.shape: \", x.shape)\n",
    "    x = x.reshape((x.shape[0],-1))\n",
    "    if debug: print(\"x.shape: \", x.shape)\n",
    "    log_probs = F.log_softmax(x, dim=(-1))\n",
    "    probs = torch.exp(log_probs)\n",
    "    if debug: \n",
    "        print(\"log_probs.shape: \", log_probs.shape)\n",
    "        print(\"log_probs.shape (reshaped): \", log_probs.view(-1, size, size).shape)\n",
    "\n",
    "    # assume squared space\n",
    "    x_lin = torch.arange(size).unsqueeze(0)\n",
    "    xx = x_lin.repeat(B,size,1)\n",
    "    if debug: print(\"xx.shape: \", xx.shape)\n",
    "    # yx \n",
    "    args = torch.cat([xx.permute(0,2,1).view(-1,size,size,1), xx.view(-1,size,size,1)], axis=3)\n",
    "    if debug: print(\"args.shape (before reshaping): \", args.shape)\n",
    "    args = args.reshape(B,-1,2)\n",
    "    if debug: print(\"args.shape (after reshaping): \", args.shape)\n",
    "    #print(\"args (after reshape): \", args)\n",
    "    index = Categorical(probs).sample()\n",
    "    arg = args[torch.arange(B), index].detach().numpy() # and this are the sampled coordinates\n",
    "    #print(\"index: \", index) \n",
    "    arg_lst = [list([a[1],a[0]])  for a in arg] # swap to xy\n",
    "    #print(\"arg_lst: \", arg_lst)\n",
    "    log_probs = log_probs.reshape(B, size, size)\n",
    "    return arg_lst, log_probs[torch.arange(B), arg[:,0], arg[:,1]], probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unravel_index(index, shape):\n",
    "    out = []\n",
    "    for dim in reversed(shape):\n",
    "        out.append(index % dim)\n",
    "        index = index // dim\n",
    "    return tuple(reversed(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_version(x, L, x_first=True, debug=True):\n",
    "    size = L\n",
    "    B = x.shape[0]\n",
    "    x = x.reshape((x.shape[0],-1))\n",
    "    log_probs = F.log_softmax(x, dim=(-1))\n",
    "    probs = torch.exp(log_probs)\n",
    "    index = Categorical(probs).sample()\n",
    "    print(\"index: \", index)\n",
    "    y, x = unravel_index(index, (size,size))\n",
    "    print(\"y, x: \", y, x)\n",
    "    arg_lst = [[xi.item(),yi.item()] for xi, yi in zip(x,y)]\n",
    "    log_prob = log_probs[torch.arange(B), index]\n",
    "    return arg_lst, log_prob, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-inf, 1., 1., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [-inf, 1., 1., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf]])\n"
     ]
    }
   ],
   "source": [
    "B = 1\n",
    "L = 4\n",
    "torch.manual_seed(1)\n",
    "value = [[0.,1.,1.,0.],\n",
    "         [0.,0.,0.,0.],\n",
    "         [0.,0.,0.,0.],\n",
    "         [0.,0.,0.,0.]]\n",
    "logits = torch.tensor([value,value])\n",
    "mask = (logits==0)\n",
    "logits = logits.masked_fill((mask).bool(), float('-inf'))\n",
    "logits = logits.reshape((logits.shape[0],-1))\n",
    "print(logits)\n",
    "\n",
    "# x first result should be (2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:  torch.Size([2, 16])\n",
      "x.shape:  torch.Size([2, 16])\n",
      "log_probs.shape:  torch.Size([2, 16])\n",
      "log_probs.shape (reshaped):  torch.Size([2, 4, 4])\n",
      "xx.shape:  torch.Size([2, 4, 4])\n",
      "args.shape (before reshaping):  torch.Size([2, 4, 4, 2])\n",
      "args.shape (after reshaping):  torch.Size([2, 16, 2])\n",
      "arg_lst:  [[1, 0], [1, 0]]\n",
      "log_prob:  tensor([-0.6931, -0.6931])\n",
      "probs:  tensor([[0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "arg_lst, log_prob, probs = old_version(logits, L)\n",
    "print(\"arg_lst: \", arg_lst)\n",
    "print(\"log_prob: \", log_prob)\n",
    "print(\"probs: \", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape:  torch.Size([2, 16])\n",
      "x.shape:  torch.Size([2, 16])\n",
      "log_probs.shape:  torch.Size([2, 16])\n",
      "log_probs.shape (reshaped):  torch.Size([2, 4, 4])\n",
      "xx.shape:  torch.Size([2, 4, 4])\n",
      "args.shape (before reshaping):  torch.Size([2, 4, 4, 2])\n",
      "args.shape (after reshaping):  torch.Size([2, 16, 2])\n",
      "arg_lst:  [[1, 0], [1, 0]]\n",
      "log_prob:  tensor([-0.6931, -0.6931])\n",
      "probs:  tensor([[0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "arg_lst, log_prob, probs = working_version(logits, L)\n",
    "print(\"arg_lst: \", arg_lst)\n",
    "print(\"log_prob: \", log_prob)\n",
    "print(\"probs: \", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  tensor([2, 1])\n",
      "y, x:  tensor([0, 0]) tensor([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[2, 0], [1, 0]],\n",
       " tensor([-0.6931, -0.6931]),\n",
       " tensor([[0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_version(logits, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
