{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from importlib import reload\n",
    "from RelationalModule import MLP_AC_networks as net\n",
    "\n",
    "from pysc2.agents import base_agent\n",
    "from pysc2.lib import actions\n",
    "from pysc2.lib import features\n",
    "from pysc2.env import sc2_env, run_loop, available_actions_printer\n",
    "from pysc2 import maps\n",
    "from absl import flags\n",
    "\n",
    "# indexes of useful layers of the screen_features\n",
    "_PLAYER_RELATIVE = features.SCREEN_FEATURES.player_relative.index \n",
    "_SELECTED = features.SCREEN_FEATURES.selected.index\n",
    "\n",
    "# Identifiers in player_relative feature layer\n",
    "_BACKGROUND = 0\n",
    "_PLAYER_FRIENDLY = 1\n",
    "_PLAYER_ALLIES = 2\n",
    "_PLAYER_NEUTRAL = 3\n",
    "_PLAYER_HOSTILE = 4\n",
    "\n",
    "# Ids of the actions that we'll use\n",
    "_NO_OP = actions.FUNCTIONS.no_op.id\n",
    "_MOVE_SCREEN = actions.FUNCTIONS.Attack_screen.id\n",
    "_SELECT_ARMY = actions.FUNCTIONS.select_army.id\n",
    "\n",
    "# Meaning of some arguments required by the actions\n",
    "_SELECT_ALL = [0]\n",
    "_NOT_QUEUED = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = sc2_env.Race(1) # 1 = terran\n",
    "agent = sc2_env.Agent(race, \"Testv0\") # NamedTuple [race, agent_name]\n",
    "\n",
    "interface_dict = dict(feature_screen=16, # screen resolution in pixel\n",
    "                      feature_minimap=16, # minimap resolution in pixel (smaller or equal to screen)\n",
    "                      action_space=\"FEATURES\") # either FEATURES or RGB - suggested: FEATURES\n",
    "\n",
    "agent_interface_format = sc2_env.parse_agent_interface_format(**interface_dict) #AgentInterfaceFormat instance\n",
    "\n",
    "game_params = dict(map_name='MoveToBeacon', # simplest minigame\n",
    "                   players=[agent], # use a list even for single player\n",
    "                   agent_interface_format=[agent_interface_format] # use a list even for single player\n",
    "                   )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an envirnoment\n",
    "env = sc2_env.SC2Env(**game_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining an high-level state\n",
    "\n",
    "For sure the most relevant informations are the position of the marine and the one of the center of the beacon. Then it might be useful to have a boolean feature telling us whether the beacon exists of not in the map and finally another flag telling us if the marine is selected or not (so that instead of relying only on the final mask for the available actions we can learn that some action, e.g. select army, are more valuable if we don't have units selected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(obs):\n",
    "    player_relative = obs[0].observation['feature_screen'][_PLAYER_RELATIVE]\n",
    "    \n",
    "    player_y, player_x = (player_relative == _PLAYER_FRIENDLY).nonzero()\n",
    "    player_pos = [player_x.mean(), player_y.mean()]\n",
    "\n",
    "    beacon_ys, beacon_xs = (player_relative == _PLAYER_NEUTRAL).nonzero()\n",
    "    if beacon_ys.any():\n",
    "        beacon_pos = [beacon_xs.mean(), beacon_ys.mean()]\n",
    "    else:\n",
    "        beacon_pos = [-1., -1.]\n",
    "        \n",
    "    beacon_exists = float(beacon_ys.any())\n",
    "    \n",
    "    selected = obs[0].observation['feature_screen'][_SELECTED]\n",
    "    is_selected = np.any((selected==1).nonzero()[0]).astype(float) \n",
    "    \n",
    "    state = np.concatenate([player_pos, beacon_pos, [beacon_exists, is_selected]])\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedNumpyArray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 1, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "                [None, None],\n",
       "                dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_relative = obs[0].observation['feature_screen'][_PLAYER_RELATIVE]\n",
    "player_relative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read:\n",
    "- 0 stays for background cells\n",
    "- 1 for cells owned by friendly units and buildings\n",
    "- 3 for cells occupied by neutral units or objects (the beacon in our case)\n",
    "\n",
    "Observation: interestingly enough, a map of 16 by 16 is good enough to represent both our unit and the beacon, so there is no need to consider greater resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedNumpyArray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "                [None, None],\n",
       "                dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected = obs[0].observation['feature_screen'][_SELECTED]\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_selected = np.any((selected==1).nonzero()[0]).astype(float) \n",
    "is_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, no unit selected at the beginning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = actions.FunctionCall(_SELECT_ARMY, [_SELECT_ALL])\n",
    "new_obs = env.step(actions=[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedNumpyArray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "                [None, None],\n",
       "                dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected = new_obs[0].observation['feature_screen'][_SELECTED]\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_selected = np.any((selected==1).nonzero()[0]).astype(float) \n",
    "is_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions\n",
    "\n",
    "Inspecting the action specifics for this map, one can see that actually all the actions are listed, so that is not going to help in defining the action space. Moreover the available actions change w.r.t. the state, that basically is whether our unit is selected or not.\n",
    "\n",
    "Reduce the action space to 3 moves:\n",
    "1. _NO_OP\n",
    "2. _SELECT_ARMY\n",
    "3. _MOVE_SCREEN\n",
    "\n",
    "Move screen is the only one that can be unavailable if the agent is not selected.\n",
    "\n",
    "We are going to compute a custom mask starting from the available actions and the ids of these 3 actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scripted_arguments(action_id, obs):\n",
    "    \n",
    "    if action_id == _SELECT_ARMY:\n",
    "        args = [_SELECT_ALL]\n",
    "        \n",
    "    elif action_id == _MOVE_SCREEN:\n",
    "        player_relative = obs[0].observation['feature_screen'][_PLAYER_RELATIVE]\n",
    "    \n",
    "        player_y, player_x = (player_relative == _PLAYER_FRIENDLY).nonzero()\n",
    "        player_pos = [int(player_x.mean()), int(player_y.mean())]\n",
    "\n",
    "        beacon_ys, beacon_xs = (player_relative == _PLAYER_NEUTRAL).nonzero()\n",
    "        \n",
    "        if beacon_ys.any():\n",
    "            coord = [int(beacon_xs.mean()), int(beacon_ys.mean())]\n",
    "        else:\n",
    "            coord = player_pos\n",
    "            \n",
    "        args = [coord]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        args = []\n",
    "        \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RelationalModule.MLP_AC_networks' from '/home/nicola/Nicola_unipd/MasterThesis/SC2-RL/RelationalModule/MLP_AC_networks.py'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = 3\n",
    "observation_space = 6\n",
    "actor = net.Actor(action_space, observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [14.  3.  4.  5.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "state = get_state(obs)\n",
    "print(\"state: \", state)\n",
    "state = torch.tensor(state).float()\n",
    "\n",
    "aa = obs[0].observation.available_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4653, -0.9888,    -inf], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs = actor(state, aa)\n",
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action:  0\n"
     ]
    }
   ],
   "source": [
    "probs = torch.exp(log_probs)\n",
    "distribution = Categorical(probs)\n",
    "a = distribution.sample().item()\n",
    "print(\"action: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_id:  _Functions.no_op\n"
     ]
    }
   ],
   "source": [
    "action_id = actor.action_dict[a]\n",
    "print(\"action_id: \", action_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args:  []\n"
     ]
    }
   ],
   "source": [
    "args = get_scripted_arguments(action_id, obs)\n",
    "print(\"args: \", args)\n",
    "action = actions.FunctionCall(action_id, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.step([action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.,  3.,  4.,  5.,  1.,  0.])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = get_state(obs)\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all this part should be included in the get_action method of the actor critic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
