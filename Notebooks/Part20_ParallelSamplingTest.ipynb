{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import torch\n",
    "from SC_Utils.train_v5 import *\n",
    "from SC_Utils.game_utils import FullObsProcesser\n",
    "import AC_modules.Networks as net\n",
    "from AC_modules.BatchedA2C import *\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# dev modules\n",
    "from AC_modules.ActorCriticArchitecture import *\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from pysc2.lib import actions as sc_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "\n",
    "class ParallelActorCritic(nn.Module):\n",
    "    \"\"\"\n",
    "    Used in FullSpaceA2C_v2\n",
    "    \n",
    "    Description of some attributes:\n",
    "    - action_table: numpy array of shape (n_actions,) \n",
    "        is a look-up table that associates an action index to its StarCraft action id\n",
    "    - spatial_arg_mask: numpy array of shape (n_actions, n_spatial_args) \n",
    "        spatial_arg_mask[a] is a mask telling which of the n_spatial_args sampled args\n",
    "        belong to action `a`. Same thing for categorical_arg_mask\n",
    "    \"\"\"\n",
    "    def __init__(self, env, spatial_model, nonspatial_model, spatial_dict, nonspatial_dict, \n",
    "                 n_features, n_channels, action_names):\n",
    "        super(ParallelActorCritic, self).__init__()\n",
    "        \n",
    "        self.action_names = action_names\n",
    "        self._set_action_table() # creates self.action_table\n",
    "        self.screen_res = env.observation_spec()[0]['feature_screen'][1:]\n",
    "        self.all_actions = env.action_spec()[0][1]\n",
    "        self.all_arguments = env.action_spec()[0][0]\n",
    "        \n",
    "        # Useful HyperParameters as attributes\n",
    "        self.n_features = n_features\n",
    "        self.n_channels = n_channels\n",
    "        action_space = len(action_names)\n",
    "        \n",
    "        # Networks\n",
    "        self.spatial_features_net = spatial_model(**spatial_dict)\n",
    "        self.nonspatial_features_net = nonspatial_model(**nonspatial_dict) \n",
    "        self.actor = SharedActor(action_space, n_features)\n",
    "        self.critic = SharedCritic(n_features)\n",
    "        self._init_arg_names()\n",
    "        self._set_spatial_arg_mask()\n",
    "        self._set_categorical_arg_mask()\n",
    "        self._init_params_nets()\n",
    "    \n",
    "    def _set_action_table(self):\n",
    "        action_ids = [sc_actions.FUNCTIONS[a_name].id for a_name in self.action_names]\n",
    "        action_table = np.array([action_ids[i] for i in range(len(action_ids))])\n",
    "        self.action_table = action_table\n",
    "    \n",
    "    def _init_arg_names(self):\n",
    "        spatial_arg_names = []\n",
    "        categorical_arg_names = []\n",
    "        categorical_sizes = []\n",
    "        act_to_arg_names = {}\n",
    "\n",
    "        for action_id in self.action_table:\n",
    "            action = self.all_actions[action_id]\n",
    "            args = action.args\n",
    "            act_to_arg_names[action_id] = [str(action.name)+\"/\"+arg.name for arg in args]\n",
    "            spatial = []\n",
    "            categorical = []\n",
    "            for arg in args:\n",
    "                arg_name = str(action.name)+\"/\"+arg.name\n",
    "                size = self.all_arguments[arg.id].sizes\n",
    "                if len(size) == 1:\n",
    "                    categorical.append(arg_name)\n",
    "                    categorical_sizes.append(size[0])\n",
    "                else:\n",
    "                    spatial.append(arg_name)\n",
    "            spatial_arg_names+=spatial\n",
    "            categorical_arg_names+=categorical\n",
    "    \n",
    "        self.spatial_arg_names = spatial_arg_names\n",
    "        self.n_spatial_args = len(spatial_arg_names)\n",
    "        self.categorical_arg_names = categorical_arg_names\n",
    "        self.n_categorical_args = len(categorical_arg_names)\n",
    "        self.categorical_sizes = np.array(categorical_sizes)\n",
    "        self.act_to_arg_names = act_to_arg_names \n",
    "\n",
    "    def _set_spatial_arg_mask(self):\n",
    "        spatial_arg_mask = np.zeros((self.action_table.shape[0], self.n_spatial_args))\n",
    "        for i, action_id in enumerate(self.action_table):\n",
    "            action_arg_names = self.act_to_arg_names[action_id]\n",
    "            spatial_arg_mask[i] = np.array([1 if self.spatial_arg_names[j] in action_arg_names else 0 \\\n",
    "                                            for j in range(self.n_spatial_args)])\n",
    "        self.spatial_arg_mask = spatial_arg_mask\n",
    "    \n",
    "    def _set_categorical_arg_mask(self):\n",
    "        categorical_arg_mask = np.zeros((self.action_table.shape[0], self.n_categorical_args))\n",
    "        for i, action_id in enumerate(self.action_table):\n",
    "            action_arg_names = self.act_to_arg_names[action_id]\n",
    "            categorical_arg_mask[i] = np.array([1 if self.categorical_arg_names[j] in action_arg_names else 0 \\\n",
    "                                            for j in range(self.n_categorical_args)])\n",
    "        self.categorical_arg_mask = categorical_arg_mask\n",
    "\n",
    "    def _init_params_nets(self):\n",
    "        n_arguments = len(self.spatial_arg_names)\n",
    "        self.spatial_params_net = ParallelSpatialParameters(self.n_channels, self.screen_res[0], n_arguments)\n",
    "        self.categorical_params_net = ParallelCategoricalNet(self.n_features, self.categorical_sizes, n_arguments)\n",
    "        \n",
    "    def pi(self, spatial_state, player_state, mask):\n",
    "        spatial_features = self.spatial_features_net(spatial_state, player_state)\n",
    "        nonspatial_features = self.nonspatial_features_net(spatial_features)\n",
    "        logits = self.actor(nonspatial_features) \n",
    "        log_probs = F.log_softmax(logits.masked_fill((mask).bool(), float('-inf')), dim=-1) \n",
    "        return log_probs, spatial_features, nonspatial_features\n",
    "    \n",
    "    def V_critic(self, spatial_state, player_state):\n",
    "        spatial_features = self.spatial_features_net(spatial_state, player_state)\n",
    "        nonspatial_features = self.nonspatial_features_net(spatial_features)\n",
    "        V = self.critic(nonspatial_features)\n",
    "        return V\n",
    "    \n",
    "    def sample_spatial_params(self, spatial_features, actions):\n",
    "        \"\"\"\n",
    "        Input\n",
    "        -----\n",
    "        spatial_features: tensor, (batch_size, n_channels, screen_res, screen_res)\n",
    "        actions: array, (batch_size,)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        arg_list: list of lists\n",
    "        \"\"\"\n",
    "        batch_size = actions.shape[0]\n",
    "        parallel_args, parallel_log_prob, _ = self.spatial_params_net(spatial_features)\n",
    "        if debug:\n",
    "            expected = actions.shape + (self.n_spatial_args, 2)\n",
    "            actual = parallel_args.shape\n",
    "            assert actual == expected, (\"unexpected parallel_args shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "            expected = actions.shape + (self.n_spatial_args,)\n",
    "            actual = parallel_log_prob.shape\n",
    "            assert actual == expected, (\"unexpected parallel_log_prob shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "\n",
    "        # Select only spatial arguments needed by sampled actions\n",
    "        arg_mask = self.spatial_arg_mask[actions,:] # shape (batch_size, n_spatial_args)\n",
    "        if debug:\n",
    "            expected = actions.shape + (self.n_spatial_args,)\n",
    "            actual = arg_mask.shape\n",
    "            assert actual == expected, (\"unexpected arg_mask shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "\n",
    "        batch_pos = arg_mask.nonzero()[0]\n",
    "        arg_pos = arg_mask.nonzero()[1]\n",
    "        args = parallel_args[batch_pos, arg_pos]\n",
    "        #arg_list = [args[batch_pos==i] for i in range(batch_size)]\n",
    "        arg_list = [list(args[batch_pos==i]) for i in range(batch_size)]\n",
    "        \n",
    "        # Compute composite log_probs of selected arguments\n",
    "        \n",
    "        # Infer device from spatial_params_net output with parallel_log_prob.is_cuda\n",
    "        if parallel_log_prob.is_cuda:\n",
    "            device = 'cuda' # Assume only 1 GPU device is used \n",
    "        else:\n",
    "            device = 'cpu'\n",
    "            \n",
    "        # for every arg index contains the index of the action that uses that parameter\n",
    "        main_action_ids = torch.tensor(self.spatial_arg_mask.nonzero()[0]).to(device)\n",
    "        if debug:\n",
    "            expected = self.n_spatial_args\n",
    "            actual = main_action_ids.shape[0]\n",
    "            assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "            \n",
    "        sum_log_prob = torch.zeros(batch_size, len(self.action_table)) # (batch_size, action_space)\n",
    "        sum_log_prob.index_add_(1, main_action_ids, parallel_log_prob)\n",
    "        sampled_actions = torch.tensor(actions) # of shape (batch_size,)\n",
    "        # sum of log_probs of the relevant parameters by\n",
    "        log_prob = sum_log_prob[torch.arange(batch_size), sampled_actions]\n",
    "        if debug:\n",
    "            expected = batch_size\n",
    "            actual = log_prob.shape[0]\n",
    "            assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "        return arg_list, log_prob\n",
    "    \n",
    "    def sample_categorical_params(self, categorical_features, actions):\n",
    "        \"\"\"\n",
    "        Input\n",
    "        -----\n",
    "        categorical_features: tensor, (batch_size, n_channels, screen_res, screen_res)\n",
    "        actions: array, (batch_size,)\n",
    "        \"\"\"\n",
    "        batch_size = actions.shape[0]\n",
    "        parallel_args, parallel_log_prob = self.categorical_params_net(categorical_features)\n",
    "        arg_mask = self.categorical_arg_mask[actions,:] # shape (batch_size, n_spatial_args)\n",
    "        \n",
    "        # select correct arguments\n",
    "        batch_pos = arg_mask.nonzero()[0]\n",
    "        arg_pos = arg_mask.nonzero()[1]\n",
    "        args = parallel_args[batch_pos, arg_pos]\n",
    "        arg_list = [list(args[batch_pos==i]) for i in range(batch_size )]\n",
    "\n",
    "        # select and sum correct log probs\n",
    "        if parallel_log_prob.is_cuda:\n",
    "            device = 'cuda' # Assume only 1 GPU device is used \n",
    "        else:\n",
    "            device = 'cpu'\n",
    "\n",
    "        # for every arg index contains the index of the action that uses that parameter\n",
    "        main_action_ids = torch.tensor(self.categorical_arg_mask.nonzero()[0]).to(device)\n",
    "        if debug:\n",
    "            expected = self.n_categorical_args\n",
    "            actual = main_action_ids.shape[0]\n",
    "            assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "\n",
    "\n",
    "\n",
    "        sum_log_prob = torch.zeros(batch_size, len(self.action_table)) # (batch_size, action_space)\n",
    "        sum_log_prob.index_add_(1, main_action_ids, parallel_log_prob)\n",
    "        sampled_actions = torch.tensor(actions) # of shape (batch_size,)\n",
    "        # sum of log_probs of the relevant parameters by\n",
    "        log_prob = sum_log_prob[torch.arange(batch_size), sampled_actions]\n",
    "        if debug:\n",
    "            expected = batch_size\n",
    "            actual = log_prob.shape[0]\n",
    "            assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "        return arg_list, log_prob\n",
    "    \n",
    "    def sample_params(self, nonspatial_features, spatial_features, actions):\n",
    "        categorical_arg_list, categorical_log_prob = self.sample_categorical_params(nonspatial_features, actions)\n",
    "        spatial_arg_list, spatial_log_prob = self.sample_spatial_params(spatial_features, actions)\n",
    "        \n",
    "        # merge arg lists\n",
    "        assert len(categorical_arg_list) == len(spatial_arg_list), (\"Expected same length for arg lists\", \\\n",
    "                                                                len(categorical_arg_list), len(spatial_arg_list))\n",
    "        \n",
    "        assert categorical_log_prob.shape == spatial_log_prob.shape, (\"Expected same log_prob shape\", \\\n",
    "                                                                 categorical_log_prob.shape, spatial_log_prob.shape)\n",
    "        log_prob = categorical_log_prob + spatial_log_prob\n",
    "        arg_list = []\n",
    "        for cat, spa in zip(categorical_arg_list, spatial_arg_list):\n",
    "            print(\"cat; \", cat)\n",
    "            print(\"spa: \", spa)\n",
    "            args = []\n",
    "            if len(cat) != 0:\n",
    "                args.append(cat)\n",
    "            args += [list(s) for s in spa] # hopefully is the right format [[arg1],[arg2],...] x batch time\n",
    "            print(\"args: \", args)\n",
    "            arg_list.append(args)\n",
    "            \n",
    "        return arg_list, log_prob\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing everything for real test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment parameters\n",
    "RESOLUTION = 32\n",
    "game_params = dict(feature_screen=RESOLUTION, feature_minimap=RESOLUTION, action_space=\"FEATURES\") \n",
    "game_names = {1:'MoveToBeacon',\n",
    "              2:'CollectMineralShards',\n",
    "              3:'DefeatRoaches',\n",
    "              4:'FindAndDefeatZerglings',\n",
    "              5:'DefeatZerglingsAndBanelings',\n",
    "              6:'CollectMineralsAndGas',\n",
    "              7:'BuildMarines'\n",
    "              }\n",
    "\n",
    "map_name = game_names[1]\n",
    "obs_proc_params = {'select_all':True}\n",
    "# 6 actions, 5 spatial params (select_rect has 2), 5 nonspatial params\n",
    "action_names = ['no_op','select_army','select_rect','Move_screen','select_point','Attack_screen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = init_game(game_params, map_name)\n",
    "op = FullObsProcesser(**obs_proc_params)\n",
    "screen_channels, minimap_channels, in_player = op.get_n_channels()\n",
    "in_channels = screen_channels + minimap_channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_model = net.FullyConvPlayerAndSpatial\n",
    "nonspatial_model = net.FullyConvNonSpatial\n",
    "# Internal features, passed inside a dictionary\n",
    "conv_channels = 32\n",
    "player_features = 16\n",
    "# Exposed features, passed outside of a dictionary\n",
    "n_channels = 48\n",
    "n_features = 256\n",
    "spatial_dict = {\"in_channels\":in_channels, 'in_player':in_player, \n",
    "                'conv_channels':conv_channels, 'player_features':player_features}\n",
    "nonspatial_dict = {'resolution':RESOLUTION, 'kernel_size':3, 'stride':2, 'n_channels':n_channels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "HPs = dict(gamma=0.99, n_steps=20, H=1e-2, \n",
    "           spatial_model=spatial_model, nonspatial_model=nonspatial_model,\n",
    "           n_features=n_features, n_channels=n_channels, action_names=action_names,\n",
    "           spatial_dict=spatial_dict, nonspatial_dict=nonspatial_dict)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    HPs['device'] = 'cuda'\n",
    "else:\n",
    "    HPs['device'] = 'cpu'\n",
    "    \n",
    "print(\"Using device \"+HPs['device'])\n",
    "\n",
    "lr = 7e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSpaceA2C_v2(FullSpaceA2C):\n",
    "    def __init__(self, env, spatial_model, nonspatial_model, spatial_dict, nonspatial_dict, \n",
    "                 n_features, n_channels, action_names, gamma=0.99, H=1e-2, n_steps=20, device='cpu'):\n",
    "        self.gamma = gamma\n",
    "        self.n_steps = n_steps\n",
    "        self.H = H\n",
    "        self.AC = ParallelActorCritic(env, spatial_model, nonspatial_model, spatial_dict, \n",
    "                                     nonspatial_dict, n_features, n_channels, action_names)\n",
    "        self.device = device \n",
    "        self.AC.to(self.device) \n",
    "        \n",
    "    def step(self, state, action_mask):\n",
    "        spatial_state = state['spatial']\n",
    "        player_state = state['player']\n",
    "        spatial_state = torch.from_numpy(spatial_state).float().to(self.device)\n",
    "        player_state = torch.from_numpy(player_state).float().to(self.device)\n",
    "        action_mask = torch.tensor(action_mask).to(self.device)\n",
    "        \n",
    "        log_probs, spatial_features, nonspatial_features = self.AC.pi(spatial_state, player_state, action_mask)\n",
    "        entropy = self.compute_entropy(log_probs)\n",
    "        probs = torch.exp(log_probs)\n",
    "        a = Categorical(probs).sample()\n",
    "        a = a.detach().cpu().numpy()\n",
    "        log_prob = log_probs[range(len(a)), a]\n",
    "        \n",
    "        args, args_log_prob = self.AC.sample_params(nonspatial_features, spatial_features, a)\n",
    "        assert args_log_prob.shape == log_prob.shape, (\"Shape mismatch between arg_log_prob and log_prob \",\\\n",
    "                                                      args_log_prob.shape, log_prob.shape)\n",
    "        log_prob = log_prob + args_log_prob\n",
    "        \n",
    "        action_id = np.array([self.AC.action_table[act] for act in a])\n",
    "        action = [actions.FunctionCall(action_id[i], args[i]) for i in range(len(action_id))]\n",
    "\n",
    "        return action, log_prob, torch.mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FullSpaceA2C_v2(env = env, **HPs)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_processes = 1\n",
    "envs = ParallelEnv(n_train_processes, game_params, map_name, obs_proc_params, agent.AC.action_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, action_mask = envs.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SC_Utils.A2C_inspection_v3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = InspectionDict(0, \"prova\", agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_state = state['spatial']\n",
    "player_state = state['player']\n",
    "spatial_state = torch.from_numpy(spatial_state).float().to(agent.device)\n",
    "player_state = torch.from_numpy(player_state).float().to(agent.device)\n",
    "action_mask = torch.tensor(action_mask).to(agent.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs, spatial_features, nonspatial_features = agent.AC.pi(spatial_state, player_state, action_mask)\n",
    "entropy = agent.compute_entropy(log_probs)\n",
    "probs = torch.exp(log_probs)\n",
    "a = Categorical(probs).sample()\n",
    "a = a.detach().cpu().numpy()\n",
    "log_prob = log_probs[range(len(a)), a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inspection ###\n",
    "step_dict = {}\n",
    "p = probs.detach().cpu().numpy() \n",
    "step_dict['action_distr'] = p\n",
    "step_dict['action_sel'] = a\n",
    "\n",
    "# Choose top 5 actions from the probabilities - check about the batch dim\n",
    "top_5 = np.argsort(p)[:,-5:]\n",
    "top_5_actions = np.array(top_5[:,::-1])[0] # some issues in accessing p if I don't call np.array()\n",
    "step_dict['top_5_actions'] = top_5_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1024)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save SPATIAL distributions only of the top 5 actions + THEIR NAMES\n",
    "_, _, log_probs = agent.AC.spatial_params_net(spatial_features)\n",
    "log_probs = log_probs.detach().cpu().numpy()[0] # batch dim 1 during inspection\n",
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, 1, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_actions # use it as a batch of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_mask = agent.AC.spatial_arg_mask[top_5_actions,:] \n",
    "arg_mask.shape #(n_actions, n_spatial_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = arg_mask.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1024)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributions = log_probs[cols]\n",
    "distributions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['select_rect/screen' 'select_rect/screen2']\n",
      "[[[-6.853835  -6.899518  -6.9091325 ... -6.901828  -6.9142013 -6.890389 ]\n",
      "  [-6.871352  -6.936567  -6.9470887 ... -6.9370604 -6.9423475 -6.8993316]\n",
      "  [-6.872617  -6.925705  -6.933766  ... -6.9363503 -6.935559  -6.8935723]\n",
      "  ...\n",
      "  [-6.8781548 -6.938509  -6.945193  ... -6.936241  -6.9353194 -6.8852797]\n",
      "  [-6.876353  -6.935577  -6.9377956 ... -6.9275503 -6.9265475 -6.8783255]\n",
      "  [-6.8391137 -6.8665137 -6.867539  ... -6.8609843 -6.8571305 -6.836329 ]]\n",
      "\n",
      " [[-6.889978  -6.8994184 -6.8955946 ... -6.8968673 -6.9060254 -6.917488 ]\n",
      "  [-6.8972144 -6.9172516 -6.918076  ... -6.920451  -6.930906  -6.947459 ]\n",
      "  [-6.900403  -6.927324  -6.933854  ... -6.934857  -6.9377623 -6.955583 ]\n",
      "  ...\n",
      "  [-6.8931293 -6.9201465 -6.927556  ... -6.929954  -6.934314  -6.9463725]\n",
      "  [-6.896717  -6.9192557 -6.9322405 ... -6.92431   -6.932617  -6.9462247]\n",
      "  [-6.913361  -6.9318533 -6.940413  ... -6.93039   -6.934319  -6.9381313]]]\n",
      "['select_point/screen']\n",
      "[[[-6.912881  -6.9016047 -6.9029346 ... -6.906811  -6.910583  -6.89083  ]\n",
      "  [-6.937413  -6.9370737 -6.938069  ... -6.9362826 -6.9472575 -6.917819 ]\n",
      "  [-6.9427233 -6.9479127 -6.9427423 ... -6.9347587 -6.942572  -6.9215894]\n",
      "  ...\n",
      "  [-6.94153   -6.942453  -6.9357314 ... -6.93213   -6.9321017 -6.9209237]\n",
      "  [-6.9441276 -6.9464746 -6.9372487 ... -6.92979   -6.9268465 -6.9177117]\n",
      "  [-6.930093  -6.9414268 -6.9367914 ... -6.9304004 -6.9309096 -6.928014 ]]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['Attack_screen/screen']\n",
      "[[[-6.920892  -6.9357295 -6.9365273 ... -6.938384  -6.945582  -6.9696035]\n",
      "  [-6.922101  -6.9467916 -6.950569  ... -6.9562225 -6.960919  -6.964574 ]\n",
      "  [-6.9085793 -6.9322486 -6.9273553 ... -6.9349494 -6.940483  -6.955709 ]\n",
      "  ...\n",
      "  [-6.9231296 -6.9450464 -6.9377527 ... -6.9383183 -6.9384537 -6.947559 ]\n",
      "  [-6.928264  -6.947637  -6.94787   ... -6.9412246 -6.9362965 -6.948016 ]\n",
      "  [-6.9394407 -6.9466686 -6.9390974 ... -6.9346414 -6.935758  -6.926746 ]]]\n"
     ]
    }
   ],
   "source": [
    "step_dict['top_5_action_distr'] = {}\n",
    "for act in top_5_actions:\n",
    "    step_dict['top_5_action_distr'][act] = {}\n",
    "    arg_mask = agent.AC.spatial_arg_mask[act,:].astype(bool)\n",
    "    arg_names = np.array(agent.AC.spatial_arg_names)[arg_mask]\n",
    "    print(arg_names)\n",
    "    distr = log_probs[arg_mask].reshape((-1,)+agent.AC.screen_res)\n",
    "    print(distr)\n",
    "    for i, name in enumerate(arg_names):\n",
    "        step_dict['top_5_action_distr'][act][name+'_distr'] = distr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([2, 4, 0, 1, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_dict['top_5_action_distr'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['select_rect/screen_distr', 'select_rect/screen2_distr'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_dict['top_5_action_distr'][2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspection_step(agent, inspector, state, action_mask):\n",
    "    spatial_state = state['spatial']\n",
    "    player_state = state['player']\n",
    "    spatial_state = torch.from_numpy(spatial_state).float().to(agent.device)\n",
    "    player_state = torch.from_numpy(player_state).float().to(agent.device)\n",
    "    action_mask = torch.tensor(action_mask).to(agent.device)\n",
    "\n",
    "    log_probs, spatial_features, nonspatial_features = agent.AC.pi(spatial_state, player_state, action_mask)\n",
    "    entropy = agent.compute_entropy(log_probs)\n",
    "    probs = torch.exp(log_probs)\n",
    "    a = Categorical(probs).sample()\n",
    "    a = a.detach().cpu().numpy()\n",
    "    log_prob = log_probs[range(len(a)), a]\n",
    "\n",
    "    ### Inspection ###\n",
    "    step_dict = {}\n",
    "    p = probs.detach().cpu().numpy() \n",
    "    step_dict['action_distr'] = p\n",
    "    step_dict['action_sel'] = a\n",
    "    \n",
    "    # Choose top 5 actions from the probabilities - check about the batch dim\n",
    "    top_5 = np.argsort(p)[:,-5:]\n",
    "    top_5_actions = np.array(top_5[:,::-1])[0] # some issues in accessing p if I don't call np.array()\n",
    "    step_dict['top_5_actions'] = top_5_actions\n",
    "    \n",
    "    # Save distributions only of the top 5 actions\n",
    "    step_dict['top_5_action_distr'] = {}\n",
    "    with torch.no_grad():\n",
    "        for act in top_5_actions:\n",
    "            step_dict['top_5_action_distr'][act] = {} # first nested level\n",
    "            arg_names = inspector.act_to_arg_names[act]\n",
    "            for arg_name in arg_names:\n",
    "                if inspector.arguments_type[arg_name] == 'spatial': # it's either 'spatial' or 'categorical'\n",
    "                    insp_arg, insp_log_prob, insp_distr = agent.AC.sample_param(spatial_features, arg_name)\n",
    "                    p = insp_distr.detach().cpu().numpy().reshape(spatial_state.shape[-2:]) \n",
    "                else:\n",
    "                    insp_arg, insp_log_prob, insp_distr = agent.AC.sample_param(nonspatial_features, arg_name)\n",
    "                    p = insp_distr.detach().cpu().numpy() \n",
    "                    \n",
    "                step_dict['top_5_action_distr'][act][arg_name+'_distr'] = p # second nested level\n",
    "                \n",
    "    ### End inspection ###\n",
    "   \n",
    "    args, args_log_prob = agent.AC.sample_params(nonspatial_features, spatial_features, a)\n",
    "    step_dict['args'] = args\n",
    "    \n",
    "    log_prob = log_prob + args_log_prob\n",
    "\n",
    "    action_id = np.array([agent.AC.action_table[act] for act in a])\n",
    "    action = [actions.FunctionCall(action_id[i], args[i]) for i in range(len(action_id))]\n",
    "\n",
    "    inspector.store_step(step_dict)\n",
    "    return action, log_prob, torch.mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat;  []\n",
      "spa:  []\n",
      "args:  []\n",
      "cat;  [0]\n",
      "spa:  [array([10,  5]), array([ 5, 27])]\n",
      "args:  [[0], [10, 5], [5, 27]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[FunctionCall(function=0, arguments=[]),\n",
       " FunctionCall(function=3, arguments=[[0], [10, 5], [5, 27]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, log_prob, entropy = agent.step(state, action_mask)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = envs.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False,  True, False,  True],\n",
       "       [False, False, False,  True, False,  True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_mask # only Move_screen and Attack_screen not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_state = state['spatial']\n",
    "player_state = state['player']\n",
    "spatial_state = torch.from_numpy(spatial_state).float().to(agent.device)\n",
    "player_state = torch.from_numpy(player_state).float().to(agent.device)\n",
    "action_mask = torch.tensor(action_mask).to(agent.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs, spatial_features, nonspatial_features = agent.AC.pi(spatial_state, player_state, action_mask)\n",
    "entropy = agent.compute_entropy(log_probs)\n",
    "probs = torch.exp(log_probs)\n",
    "a = Categorical(probs).sample()\n",
    "a = a.detach().cpu().numpy()\n",
    "log_prob = log_probs[range(len(a)), a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_arg_list, spatial_arg_list = agent.AC.sample_params(nonspatial_features, spatial_features, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([11, 30]), array([ 3, 21])], []]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0], [11, 30], [3, 21]], [[1]]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_list = []\n",
    "for cat, spa in zip(categorical_arg_list, spatial_arg_list):\n",
    "    args = [cat]+[list(s) for s in spa]\n",
    "    arg_list.append(args)\n",
    "arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_id = np.array([agent.AC.action_table[act] for act in a])\n",
    "action_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = [sc_actions.FunctionCall(action_id[i], arg_list[i]) for i in range(len(action_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = envs.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.AC.spatial_params_net.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_args, spatial_log_prob = agent.AC.sample_spatial_params(spatial_features, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1, 23]]), array([[15,  3]])]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.9371, -6.7936], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3695, -1.3670], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob # these 2 can be summed up easily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the same thing for non-spatial params\n",
    "\n",
    "Reference code:\n",
    "```python\n",
    "class CategoricalNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features, size, hiddens=[256]):\n",
    "        super(CategoricalNet, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(nn.Linear(n_features, hiddens[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "            \n",
    "        for i in range(0,len(hiddens)-1):\n",
    "            layers.append(nn.Linear(hiddens[i], hiddens[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Linear(hiddens[-1], size))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, state_rep):\n",
    "        logits = self.net(state_rep)\n",
    "        log_probs = F.log_softmax(logits, dim=(-1))\n",
    "        probs = torch.exp(log_probs)\n",
    "        arg = Categorical(probs).sample()\n",
    "        arg = arg.detach().cpu().numpy()\n",
    "        return arg.reshape(-1,1), log_probs[range(len(arg)), arg], log_probs\n",
    "```\n",
    "\n",
    "Changes:\n",
    "- receive an array of sizes\n",
    "- consider the max size and get the logits of shape (batch_size, n_arguments, sizes)\n",
    "- make a mask of shape (n_arguments, sizes) and repeat it along batch_size\n",
    "    to use like logits.masked_fill(mask.bool(), float('-inf')) before the softmax\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = agent.AC.categorical_sizes\n",
    "categorical_params_net = ParallelCategoricalNet(256, sizes, agent.AC.n_categorical_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 2, 0]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_args, parallel_log_prob = categorical_params_net(nonspatial_features)\n",
    "parallel_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_mask = agent.AC.categorical_arg_mask[a,:] # shape (batch_size, n_spatial_args)\n",
    "if debug:\n",
    "    expected = a.shape + (agent.AC.n_categorical_args,)\n",
    "    actual = arg_mask.shape\n",
    "    assert actual == expected, (\"unexpected arg_mask shape; actual vs expected: \", \\\n",
    "                                actual, expected)\n",
    "\n",
    "arg_mask      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = arg_mask.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pos:  [0 1]\n",
      "arg_pos:  [3 3]\n",
      "args:  [0 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0], [2]]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select correct action\n",
    "batch_pos = arg_mask.nonzero()[0]\n",
    "print(\"batch_pos: \", batch_pos)\n",
    "arg_pos = arg_mask.nonzero()[1]\n",
    "print(\"arg_pos: \", arg_pos)\n",
    "args = parallel_args[batch_pos, arg_pos]\n",
    "print(\"args: \", args)\n",
    "arg_list = [list(args[batch_pos==i]) for i in range(batch_size )]\n",
    "arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7394, -0.7430, -0.7037, -1.3580, -0.7493],\n",
       "        [-0.7369, -0.7440, -0.7031, -1.3919, -0.7464]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select and sum correct log probs\n",
    "\n",
    "if parallel_log_prob.is_cuda:\n",
    "    device = 'cuda' # Assume only 1 GPU device is used \n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "# for every arg index contains the index of the action that uses that parameter\n",
    "main_action_ids = torch.tensor(agent.AC.categorical_arg_mask.nonzero()[0]).to(device)\n",
    "if debug:\n",
    "    expected = agent.AC.n_categorical_args\n",
    "    actual = main_action_ids.shape[0]\n",
    "    assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                actual, expected)\n",
    "\n",
    "\n",
    "            \n",
    "sum_log_prob = torch.zeros(batch_size, len(agent.AC.action_table)) # (batch_size, action_space)\n",
    "sum_log_prob.index_add_(1, main_action_ids, parallel_log_prob)\n",
    "sampled_actions = torch.tensor(a) # of shape (batch_size,)\n",
    "# sum of log_probs of the relevant parameters by\n",
    "log_prob = sum_log_prob[torch.arange(batch_size), sampled_actions]\n",
    "if debug:\n",
    "    expected = batch_size\n",
    "    actual = log_prob.shape[0]\n",
    "    assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                actual, expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3580, -1.3919], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ced5f7c27bc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_log_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonspatial_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs_log_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Use only entropy of main actions for regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#entropy = entropy + args_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "args, args_log_prob, args_entropy = self.get_arguments(spatial_features, nonspatial_features, a)\n",
    "log_prob = log_prob + args_log_prob\n",
    "# Use only entropy of main actions for regularization\n",
    "#entropy = entropy + args_entropy\n",
    "\n",
    "action_id = np.array([self.AC.action_dict[act] for act in a])\n",
    "action = [actions.FunctionCall(action_id[i], args[i]) for i in range(len(action_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actions = env.action_spec()[0][1]\n",
    "all_arguments = env.action_spec()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_table(action_names):\n",
    "    action_ids = [sc_actions.FUNCTIONS[a_name].id for a_name in action_names]\n",
    "    action_table = np.array([action_ids[i] for i in range(len(action_ids))])\n",
    "    return action_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   7,   3, 331,   2,  12])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_names = ['no_op','select_army','select_rect','Move_screen','select_point','Attack_screen']\n",
    "action_table = get_action_table(action_names) \n",
    "action_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial_arg_names:  ['select_rect/screen', 'select_rect/screen2', 'Move_screen/screen', 'select_point/screen', 'Attack_screen/screen']\n",
      "Number of args:  5\n",
      "categorical_arg_names:  ['select_army/select_add', 'select_rect/select_add', 'Move_screen/queued', 'select_point/select_point_act', 'Attack_screen/queued']\n",
      "Number of args:  5\n"
     ]
    }
   ],
   "source": [
    "# now we need to get all the possible arguments counted twice if they belong to different actions\n",
    "def _init_arg_names(action_table):\n",
    "    \"\"\"\n",
    "    Add self as first argument and use it as a class method in the AC.\n",
    "    Assume all_actions and all_arguments as attributes of the class (add self. in front of them)\n",
    "    Also instead of returning the results, add them as attributes of the class.\n",
    "    \"\"\"\n",
    "    spatial_arg_names = []\n",
    "    categorical_arg_names = []\n",
    "    categorical_sizes = []\n",
    "    act_to_arg_names = {}\n",
    "\n",
    "    for action_id in action_table:\n",
    "        action = all_actions[action_id]\n",
    "        args = action.args\n",
    "        act_to_arg_names[action_id] = [str(action.name)+\"/\"+arg.name for arg in args]\n",
    "        spatial = []\n",
    "        categorical = []\n",
    "        for arg in args:\n",
    "            arg_name = str(action.name)+\"/\"+arg.name\n",
    "            size = all_arguments[arg.id].sizes\n",
    "            if len(size) == 1:\n",
    "                categorical.append(arg_name)\n",
    "                categorical_sizes.append(size)\n",
    "            else:\n",
    "                spatial.append(arg_name)\n",
    "        spatial_arg_names+=spatial\n",
    "        categorical_arg_names+=categorical\n",
    "    return spatial_arg_names, categorical_arg_names, act_to_arg_names\n",
    "\n",
    "spatial_arg_names, categorical_arg_names, act_to_arg_names = _init_arg_names(action_table)\n",
    "        \n",
    "print('spatial_arg_names: ', spatial_arg_names)\n",
    "print(\"Number of args: \", len(spatial_arg_names))\n",
    "print('categorical_arg_names: ', categorical_arg_names)\n",
    "print(\"Number of args: \", len(categorical_arg_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatial_arg_mask(action_table, spatial_arg_names):\n",
    "    spatial_arg_mask = np.zeros((action_table.shape[0], len(spatial_arg_names)))\n",
    "    for i, action_id in enumerate(action_table):\n",
    "        action_arg_names = act_to_arg_names[action_id]\n",
    "        spatial_arg_mask[i] = np.array([1 if spatial_arg_names[j] in action_arg_names else 0 for j in range(len(spatial_arg_names))])\n",
    "    return spatial_arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spatial_arg_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-47ed0a9a4fe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspatial_arg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_spatial_arg_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatial_arg_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mspatial_arg_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spatial_arg_names' is not defined"
     ]
    }
   ],
   "source": [
    "spatial_arg_mask = get_spatial_arg_mask(action_table, spatial_arg_names)\n",
    "spatial_arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_arg_mask(action_table, categorical_arg_names):\n",
    "    categorical_arg_mask = np.zeros((action_table.shape[0], len(categorical_arg_names)))\n",
    "    for i, action_id in enumerate(action_table):\n",
    "        action_arg_names = act_to_arg_names[action_id]\n",
    "        categorical_arg_mask[i] = np.array([1 if categorical_arg_names[j] in action_arg_names else 0 for j in range(len(categorical_arg_names))])\n",
    "    return categorical_arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_arg_mask = get_categorical_arg_mask(action_table, categorical_arg_names)\n",
    "categorical_arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.array([2,1,0])\n",
    "spatial_arg_mask[actions,:] # use this to access args or mask log probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 32, 32])\n",
      "args:  (3, 5, 2) \n",
      " [[[14 16]\n",
      "  [13 25]\n",
      "  [ 6 25]\n",
      "  [28  4]\n",
      "  [ 3 20]]\n",
      "\n",
      " [[13 12]\n",
      "  [16 11]\n",
      "  [ 9 18]\n",
      "  [20 29]\n",
      "  [11 15]]\n",
      "\n",
      " [[15 18]\n",
      "  [11 20]\n",
      "  [ 5 21]\n",
      "  [18 28]\n",
      "  [ 7  9]]]\n",
      "log_prob:  tensor([[-6.7258, -6.9170, -7.1031, -7.2827, -7.0330],\n",
      "        [-6.7674, -7.1977, -6.7109, -6.7441, -6.9934],\n",
      "        [-6.9490, -6.9059, -6.5702, -6.8146, -7.0296]], grad_fn=<ViewBackward>)\n",
      "log_probs.shape:  torch.Size([3, 5, 1024])\n"
     ]
    }
   ],
   "source": [
    "B = 3\n",
    "n_channels = 16\n",
    "res = 32\n",
    "n_arguments = 5\n",
    "x = torch.rand(B,n_channels,res,res)\n",
    "print(x.shape)\n",
    "spatial_net = ParallelSpatialParameters(n_channels, res, n_arguments)\n",
    "args, log_prob, log_probs = spatial_net(x) # I can forget about log_probs, because I don't compute their entropy\n",
    "print('args: ', args.shape, '\\n', args) # lipst of lists\n",
    "print('log_prob: ', log_prob)\n",
    "print('log_probs.shape: ', log_probs.shape) # (B, res**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.array([2,1,3])\n",
    "arg_mask = spatial_arg_mask[actions,:] # use this to access args or mask log probs\n",
    "arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pos = arg_mask.nonzero()[0]\n",
    "batch_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_pos = arg_mask.nonzero()[1]\n",
    "arg_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 16],\n",
       "       [ 9, 15],\n",
       "       [21,  3]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_selected = args[batch_pos, arg_pos]\n",
    "args_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 7, 16],\n",
       "        [ 9, 15]]), array([], shape=(0, 2), dtype=int64), array([[21,  3]])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of them based on batch_pos\n",
    "arg_list = [args_selected[batch_pos==i] for i in range(B)]\n",
    "arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_action_ids = torch.tensor(spatial_arg_mask.nonzero()[0])\n",
    "main_action_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000, -14.0128,  -7.1679,  -6.9187,  -7.1077],\n",
       "        [  0.0000,   0.0000, -14.0146,  -6.6906,  -7.0085,  -6.6435],\n",
       "        [  0.0000,   0.0000, -13.7723,  -6.5021,  -6.9189,  -6.6367]],\n",
       "       grad_fn=<IndexAddBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actions = len(action_table)\n",
    "sum_log_prob = torch.zeros(B, n_actions)\n",
    "sum_log_prob.index_add_(1, main_action_ids, log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-14.0128,   0.0000,  -6.5021], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if you sample actions\n",
    "samples = torch.tensor(actions) # of shape (batch_size,)\n",
    "# you can get the sum of log_probs of the relevant parameters by\n",
    "sum_log_prob[torch.arange(B), samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexander code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9e13e84391e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#which positions are owned by which argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain_action_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mn_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_action_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;31m# all possible unique elements in main_action_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#which positions are owned by which argument\n",
    "main_action_ids = torch.tensor([0, 0, 1, 1, 2])\n",
    "n_arguments = len(main_action_ids)\n",
    "n_actions = 3 # all possible unique elements in main_action_ids\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = torch.arange(batch_size*n_arguments).float().view(batch_size, n_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.1397, -7.0619, -6.8159,  ..., -6.9571, -6.8822, -6.6614],\n",
       "         [-7.2100, -6.8245, -6.8680,  ..., -7.1253, -7.2476, -6.8876],\n",
       "         [-6.7696, -7.1995, -6.9974,  ..., -6.8698, -6.7482, -6.2425],\n",
       "         [-6.5937, -6.6011, -6.9123,  ..., -6.9024, -7.0177, -6.8117],\n",
       "         [-6.7422, -6.7434, -6.5691,  ..., -7.0115, -7.1403, -7.3158]],\n",
       "\n",
       "        [[-6.9153, -6.7841, -6.7303,  ..., -6.9872, -6.8430, -6.7925],\n",
       "         [-6.9692, -6.6834, -7.1690,  ..., -6.9372, -7.2004, -6.9948],\n",
       "         [-6.7372, -7.2126, -7.0391,  ..., -6.6308, -6.5861, -6.3031],\n",
       "         [-6.7129, -6.7453, -6.8583,  ..., -6.9967, -7.1100, -6.7289],\n",
       "         [-6.8226, -6.8818, -6.7086,  ..., -7.1040, -6.8994, -7.3203]],\n",
       "\n",
       "        [[-7.0819, -6.9388, -7.0197,  ..., -6.8330, -6.8524, -7.0321],\n",
       "         [-6.9040, -6.7202, -7.0060,  ..., -7.0316, -7.0382, -6.7653],\n",
       "         [-6.7028, -6.9682, -6.9849,  ..., -6.4215, -6.4388, -6.1832],\n",
       "         [-6.6856, -6.8304, -6.7160,  ..., -7.1000, -7.0478, -6.8546],\n",
       "         [-6.7928, -6.5417, -6.7195,  ..., -7.4844, -7.2196, -7.0488]]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  5.,  4.],\n",
       "        [11., 15.,  9.],\n",
       "        [21., 25., 14.],\n",
       "        [31., 35., 19.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_log_probs = torch.zeros(batch_size, n_actions)\n",
    "sum_log_probs.index_add_(1, main_action_ids, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1., 15., 21., 19.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if you sample actions\n",
    "samples = torch.tensor([0, 1, 0, 2]) # of shape (batch_size,)\n",
    "# you can get the sum of log_probs of the relevant parameters by\n",
    "sum_log_probs[torch.arange(batch_size), samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other part\n",
    "\n",
    "Values are all the possible values that each argument can assume; n_values in reality would be res**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "n_values = 6 # possible range of sample_value_ids\n",
    "log_probs = torch.arange(batch_size*n_arguments*n_values).float().view(batch_size, n_arguments, n_values)\n",
    "\n",
    "# We sample based on these log_probs\n",
    "sample_value_ids = torch.tensor([\n",
    "    [0, 0, 1, 1, 2],\n",
    "    [3, 3, 4, 4, 5],\n",
    "    [0, 1, 2, 3, 4],\n",
    "    [5, 4, 3, 2, 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   1.,   2.,   3.,   4.,   5.],\n",
       "         [  6.,   7.,   8.,   9.,  10.,  11.],\n",
       "         [ 12.,  13.,  14.,  15.,  16.,  17.],\n",
       "         [ 18.,  19.,  20.,  21.,  22.,  23.],\n",
       "         [ 24.,  25.,  26.,  27.,  28.,  29.]],\n",
       "\n",
       "        [[ 30.,  31.,  32.,  33.,  34.,  35.],\n",
       "         [ 36.,  37.,  38.,  39.,  40.,  41.],\n",
       "         [ 42.,  43.,  44.,  45.,  46.,  47.],\n",
       "         [ 48.,  49.,  50.,  51.,  52.,  53.],\n",
       "         [ 54.,  55.,  56.,  57.,  58.,  59.]],\n",
       "\n",
       "        [[ 60.,  61.,  62.,  63.,  64.,  65.],\n",
       "         [ 66.,  67.,  68.,  69.,  70.,  71.],\n",
       "         [ 72.,  73.,  74.,  75.,  76.,  77.],\n",
       "         [ 78.,  79.,  80.,  81.,  82.,  83.],\n",
       "         [ 84.,  85.,  86.,  87.,  88.,  89.]],\n",
       "\n",
       "        [[ 90.,  91.,  92.,  93.,  94.,  95.],\n",
       "         [ 96.,  97.,  98.,  99., 100., 101.],\n",
       "         [102., 103., 104., 105., 106., 107.],\n",
       "         [108., 109., 110., 111., 112., 113.],\n",
       "         [114., 115., 116., 117., 118., 119.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_log_probs = log_probs.view(batch_size*n_arguments, n_values) \\\n",
    "[torch.arange(batch_size*n_arguments), sample_value_ids.flatten()] \\\n",
    ".view(batch_size, n_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   6.,  13.,  19.,  26.],\n",
       "        [ 33.,  39.,  46.,  52.,  59.],\n",
       "        [ 60.,  67.,  74.,  81.,  88.],\n",
       "        [ 95., 100., 105., 110., 115.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPALA stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.6373, -6.6354, -6.5852,  ..., -7.3167, -7.3601, -7.0510],\n",
       "         [-7.2242, -7.4536, -6.9138,  ..., -6.5512, -7.1419, -6.7743],\n",
       "         [-7.2772, -6.5754, -7.0199,  ..., -7.3377, -7.2435, -7.1724],\n",
       "         [-6.6585, -7.2519, -6.6346,  ..., -7.3207, -7.0605, -7.4516],\n",
       "         [-6.6625, -7.1998, -6.5355,  ..., -6.8263, -7.0948, -6.7885]],\n",
       "\n",
       "        [[-7.2413, -7.2254, -6.4852,  ..., -6.7026, -6.8807, -6.5622],\n",
       "         [-7.4441, -6.4725, -7.1917,  ..., -6.8488, -7.1549, -7.1132],\n",
       "         [-6.9159, -6.9486, -6.6743,  ..., -6.5905, -6.8584, -6.6929],\n",
       "         [-7.4537, -7.3384, -6.8046,  ..., -6.9212, -6.6085, -7.2997],\n",
       "         [-7.1154, -6.9548, -6.8218,  ..., -7.2685, -6.5803, -6.5897]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "n_actions = 4 # main actions\n",
    "n_args = 5 # spatial args\n",
    "res = 32\n",
    "\n",
    "# like if they were no_op, Move_Screen, select_rect, select_point for example\n",
    "spatial_arg_mask = torch.tensor([\n",
    "    [0,0,0,0,0],\n",
    "    [0,1,0,0,0],\n",
    "    [0,0,1,1,0],\n",
    "    [0,0,0,0,1]\n",
    "], dtype=torch.bool)\n",
    "\n",
    "# assume this is the output of the learner net and we need to access only the log_probs of the arguments \n",
    "# already sampled by the actors\n",
    "logits = torch.rand((batch_size, n_args, res**2))\n",
    "log_probs = F.log_softmax(logits, dim=-1)\n",
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "probs = torch.exp(log_probs)\n",
    "torch.sum(probs, axis =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([796, 698, 677, 127])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# say we sample as main actions \n",
    "main_actions = torch.tensor([2,2])\n",
    "# and as sampled arguments we have\n",
    "indexes = Categorical(probs).sample() # sample all args for batch_size times\n",
    "mask = spatial_arg_mask[main_actions,:]\n",
    "sampled_args_indexes = indexes[mask]\n",
    "sampled_args_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2],\n",
       "        [0, 3],\n",
       "        [1, 2],\n",
       "        [1, 3]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_indexes:  tensor([0, 0, 1, 1])\n",
      "arg_indexes:  tensor([2, 3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# to use them we need more info, because it's not a 1 to 1 correspondence, since every action can have between 0 and 2 spatial arguments \n",
    "# and up to 3 arguments in total (considering the categorical once)\n",
    "# basically we need to know how to split them, associating to them a batch index and an arg index\n",
    "batch_indexes = mask.nonzero()[:,0]\n",
    "# first arg belongs to second batch element, second and third args to third batch element and \n",
    "# fourth and fifth args to fourth batch element\n",
    "print(\"batch_indexes: \", batch_indexes)\n",
    "arg_indexes = mask.nonzero()[:,1]\n",
    "# this one says from with position along the argument axis the argument comes from\n",
    "print(\"arg_indexes: \", arg_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.8043, -6.8512, -6.5093, -6.5309])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_log_prob = log_probs[batch_indexes, arg_indexes, sampled_args_indexes]\n",
    "sampled_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-13.6555, -13.0402])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the other thing that we have to do is to sum together the log_probs of the arguments \n",
    "# that belong to the same action\n",
    "sum_log_prob = torch.zeros(batch_size)\n",
    "sum_log_prob.index_add_(0, batch_indexes, sampled_log_prob)\n",
    "# actions[0] = no_op has no arguments -> default value of 0\n",
    "# actions[1]=select_point has 1 argument (the first one stored in sampled_log_prob)\n",
    "# actions[2]=select_rect has 2 arguments (second and third stored)\n",
    "# actions[3]=select_rect has 2 arguments (fourth and fifth stored)\n",
    "sum_log_prob # no padding needed for this, it's always of shape (batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last problem that we have is how to communicate a variable number of arguments through a torch buffer \n",
    "# (tensor of fixed size) - padding?\n",
    "max_num_spatial_args = torch.max(spatial_arg_mask.sum(axis=1)) * batch_size\n",
    "max_num_spatial_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([796, 698, 677, 127])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([796, 698, 677, 127])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_to_len(t, length, fill_value=-1):\n",
    "    \"\"\" Assuming t of shape L <= length \"\"\"\n",
    "    assert t.shape[0] <= length, \"tensor too long to be padded\"\n",
    "    padding = torch.ones(length-len(t), dtype=torch.int64)*-1\n",
    "    padded_t = torch.cat([t, padding])\n",
    "    return padded_t\n",
    "\n",
    "paddded_sampled_args_indexes = pad_to_len(sampled_args_indexes, max_num_spatial_args)\n",
    "print(paddded_sampled_args_indexes)\n",
    "sampled_args_indexes = paddded_sampled_args_indexes[paddded_sampled_args_indexes!=-1]\n",
    "sampled_args_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of variables to be passed through the buffer \n",
    "-> they also need to be given as output in the agent_output dictionary\n",
    "- main_actions # sampling involved\n",
    "- sum_log_prob # actor weights used\n",
    "- spatial_sampled_args_indexes # sampling involved\n",
    "\n",
    "Tecnically speaking we can recompute batch_indexes and arg_indexes inside the learner's step, as long as \n",
    "we have access to the spatial_arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's simulate the learner \n",
    "B = 2 # batch of 2 samples\n",
    "T = 3 # 3 timesteps\n",
    "# time first\n",
    "main_actions = torch.tensor([\n",
    "                            [0,3],\n",
    "                            [2,1],\n",
    "                            [2,2]\n",
    "])\n",
    "\n",
    "padded_spatial_indexes = torch.tensor([\n",
    "    [213,-1,-1,-1],\n",
    "    [1019,595,913,-1],\n",
    "    [796, 698, 677, 127]\n",
    "])\n",
    "\n",
    "spatial_log_probs = F.log_softmax(torch.rand((T, B, n_args, res**2)), dim=-1).view(B*T, n_args, res**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to compute the new sum_log_prob, assuming that spatial_log_probs are coming from the learner's weight instead of the actor ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False,  True,  True, False],\n",
       "        [False,  True, False, False, False],\n",
       "        [False, False,  True,  True, False],\n",
       "        [False, False,  True,  True, False]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = spatial_arg_mask[main_actions,:].view(-1,n_args) # merge time and batch dims\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 213, 1019,  595,  913,  796,  698,  677,  127])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_indexes = padded_spatial_indexes[padded_spatial_indexes!=-1]\n",
    "spatial_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_index = mask.nonzero()[:,0]\n",
    "arg_index = mask.nonzero()[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.2616, -7.2981, -6.6641, -6.9051, -6.7400, -7.3465, -6.8952, -6.6582])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_log_prob = spatial_log_probs[batch_index, arg_index, spatial_indexes]\n",
    "spatial_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.0000,  -7.2616, -13.9621,  -6.9051, -14.0865, -13.5534])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_log_prob = torch.zeros(B*T)\n",
    "sum_log_prob.index_add_(0, batch_index, spatial_log_prob)\n",
    "sum_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
