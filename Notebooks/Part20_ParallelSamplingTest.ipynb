{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import torch\n",
    "from SC_Utils.train_v5 import *\n",
    "from SC_Utils.game_utils import FullObsProcesser\n",
    "import AC_modules.Networks as net\n",
    "from AC_modules.BatchedA2C import *\n",
    "import torch\n",
    "\n",
    "# dev modules\n",
    "from AC_modules.ActorCriticArchitecture import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from pysc2.lib import actions as sc_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "\n",
    "class ParallelActorCritic(nn.Module):\n",
    "    \"\"\"\n",
    "    Used in ?\n",
    "    \n",
    "    Description of some attributes:\n",
    "    - action_table: numpy array of shape (n_actions,) \n",
    "        is a look-up table that associates an action index to its StarCraft action id\n",
    "    - spatial_arg_mask: numpy array of shape (n_actions, n_spatial_args) \n",
    "        spatial_arg_mask[a] is a mask telling which of the n_spatial_args sampled args\n",
    "        belong to action `a`. Same thing for categorical_arg_mask\n",
    "    \"\"\"\n",
    "    def __init__(self, env, spatial_model, nonspatial_model, spatial_dict, nonspatial_dict, \n",
    "                 n_features, n_channels, action_names):\n",
    "        super(ParallelActorCritic, self).__init__()\n",
    "        \n",
    "        self.action_names = action_names\n",
    "        self._set_action_table() # creates self.action_table\n",
    "        self.screen_res = env.observation_spec()[0]['feature_screen'][1:]\n",
    "        self.all_actions = env.action_spec()[0][1]\n",
    "        self.all_arguments = env.action_spec()[0][0]\n",
    "        \n",
    "        # Useful HyperParameters as attributes\n",
    "        self.n_features = n_features\n",
    "        self.n_channels = n_channels\n",
    "        action_space = len(action_names)\n",
    "        \n",
    "        # Networks\n",
    "        self.spatial_features_net = spatial_model(**spatial_dict)\n",
    "        self.nonspatial_features_net = nonspatial_model(**nonspatial_dict) \n",
    "        self.actor = SharedActor(action_space, n_features)\n",
    "        self.critic = SharedCritic(n_features)\n",
    "        self._init_arg_names()\n",
    "        self._set_spatial_arg_mask()\n",
    "        self._set_categorical_arg_mask()\n",
    "        self._init_params_nets()\n",
    "    \n",
    "    def _set_action_table(self):\n",
    "        action_ids = [sc_actions.FUNCTIONS[a_name].id for a_name in self.action_names]\n",
    "        action_table = np.array([action_ids[i] for i in range(len(action_ids))])\n",
    "        self.action_table = action_table\n",
    "    \n",
    "    def _init_arg_names(self):\n",
    "        spatial_arg_names = []\n",
    "        categorical_arg_names = []\n",
    "        categorical_sizes = []\n",
    "        act_to_arg_names = {}\n",
    "\n",
    "        for action_id in self.action_table:\n",
    "            action = self.all_actions[action_id]\n",
    "            args = action.args\n",
    "            act_to_arg_names[action_id] = [str(action.name)+\"/\"+arg.name for arg in args]\n",
    "            spatial = []\n",
    "            categorical = []\n",
    "            for arg in args:\n",
    "                arg_name = str(action.name)+\"/\"+arg.name\n",
    "                size = self.all_arguments[arg.id].sizes\n",
    "                if len(size) == 1:\n",
    "                    categorical.append(arg_name)\n",
    "                    categorical_sizes.append(size[0])\n",
    "                else:\n",
    "                    spatial.append(arg_name)\n",
    "            spatial_arg_names+=spatial\n",
    "            categorical_arg_names+=categorical\n",
    "    \n",
    "        self.spatial_arg_names = spatial_arg_names\n",
    "        self.n_spatial_args = len(spatial_arg_names)\n",
    "        self.categorical_arg_names = categorical_arg_names\n",
    "        self.n_categorical_args = len(categorical_arg_names)\n",
    "        self.categorical_sizes = np.array(categorical_sizes)\n",
    "        self.act_to_arg_names = act_to_arg_names \n",
    "\n",
    "    def _set_spatial_arg_mask(self):\n",
    "        spatial_arg_mask = np.zeros((self.action_table.shape[0], self.n_spatial_args))\n",
    "        for i, action_id in enumerate(self.action_table):\n",
    "            action_arg_names = self.act_to_arg_names[action_id]\n",
    "            spatial_arg_mask[i] = np.array([1 if self.spatial_arg_names[j] in action_arg_names else 0 \\\n",
    "                                            for j in range(self.n_spatial_args)])\n",
    "        self.spatial_arg_mask = spatial_arg_mask\n",
    "    \n",
    "    def _set_categorical_arg_mask(self):\n",
    "        categorical_arg_mask = np.zeros((self.action_table.shape[0], self.n_categorical_args))\n",
    "        for i, action_id in enumerate(self.action_table):\n",
    "            action_arg_names = self.act_to_arg_names[action_id]\n",
    "            categorical_arg_mask[i] = np.array([1 if self.categorical_arg_names[j] in action_arg_names else 0 \\\n",
    "                                            for j in range(self.n_categorical_args)])\n",
    "        self.categorical_arg_mask = categorical_arg_mask\n",
    "\n",
    "    def _init_params_nets(self):\n",
    "        n_arguments = len(self.spatial_arg_names)\n",
    "        self.spatial_params_net = ParallelSpatialParameters(self.n_channels, self.screen_res[0], n_arguments)\n",
    "        self.categorical_params_net = ParallelCategoricalNet(self.n_features, self.categorical_sizes, n_arguments)\n",
    "        \n",
    "    def pi(self, spatial_state, player_state, mask):\n",
    "        spatial_features = self.spatial_features_net(spatial_state, player_state)\n",
    "        nonspatial_features = self.nonspatial_features_net(spatial_features)\n",
    "        logits = self.actor(nonspatial_features) \n",
    "        log_probs = F.log_softmax(logits.masked_fill((mask).bool(), float('-inf')), dim=-1) \n",
    "        return log_probs, spatial_features, nonspatial_features\n",
    "    \n",
    "    def V_critic(self, spatial_state, player_state):\n",
    "        spatial_features = self.spatial_features_net(spatial_state, player_state)\n",
    "        nonspatial_features = self.nonspatial_features_net(spatial_features)\n",
    "        V = self.critic(nonspatial_features)\n",
    "        return V\n",
    "    \n",
    "    def sample_spatial_params(self, spatial_features, actions):\n",
    "        \"\"\"\n",
    "        Input\n",
    "        -----\n",
    "        spatial_features: tensor, (batch_size, n_channels, screen_res, screen_res)\n",
    "        actions: array, (batch_size,)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        arg_list: list of lists\n",
    "        \"\"\"\n",
    "        batch_size = actions.shape[0]\n",
    "        parallel_args, parallel_log_prob, _ = self.spatial_params_net(spatial_features)\n",
    "        if debug:\n",
    "            expected = actions.shape + (self.n_spatial_args, 2)\n",
    "            actual = parallel_args.shape\n",
    "            assert actual == expected, (\"unexpected parallel_args shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "            expected = actions.shape + (self.n_spatial_args,)\n",
    "            actual = parallel_log_prob.shape\n",
    "            assert actual == expected, (\"unexpected parallel_log_prob shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "\n",
    "        # Select only spatial arguments needed by sampled actions\n",
    "        arg_mask = self.spatial_arg_mask[actions,:] # shape (batch_size, n_spatial_args)\n",
    "        if debug:\n",
    "            expected = actions.shape + (self.n_spatial_args,)\n",
    "            actual = arg_mask.shape\n",
    "            assert actual == expected, (\"unexpected arg_mask shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "\n",
    "        batch_pos = arg_mask.nonzero()[0]\n",
    "        arg_pos = arg_mask.nonzero()[1]\n",
    "        args = parallel_args[batch_pos, arg_pos]\n",
    "        #arg_list = [args[batch_pos==i] for i in range(batch_size)]\n",
    "        arg_list = [list(args[batch_pos==i]) for i in range(batch_size)]\n",
    "        \n",
    "        # Compute composite log_probs of selected arguments\n",
    "        \n",
    "        # Infer device from spatial_params_net output with parallel_log_prob.is_cuda\n",
    "        if parallel_log_prob.is_cuda:\n",
    "            device = 'cuda' # Assume only 1 GPU device is used \n",
    "        else:\n",
    "            device = 'cpu'\n",
    "            \n",
    "        # for every arg index contains the index of the action that uses that parameter\n",
    "        main_action_ids = torch.tensor(self.spatial_arg_mask.nonzero()[0]).to(device)\n",
    "        if debug:\n",
    "            expected = self.n_spatial_args\n",
    "            actual = main_action_ids.shape[0]\n",
    "            assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "            \n",
    "        sum_log_prob = torch.zeros(batch_size, len(self.action_table)) # (batch_size, action_space)\n",
    "        sum_log_prob.index_add_(1, main_action_ids, parallel_log_prob)\n",
    "        sampled_actions = torch.tensor(actions) # of shape (batch_size,)\n",
    "        # sum of log_probs of the relevant parameters by\n",
    "        log_prob = sum_log_prob[torch.arange(batch_size), sampled_actions]\n",
    "        if debug:\n",
    "            expected = batch_size\n",
    "            actual = log_prob.shape[0]\n",
    "            assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "        return arg_list, log_prob\n",
    "    \n",
    "    def sample_categorical_params(self, categorical_features, actions):\n",
    "        \"\"\"\n",
    "        Input\n",
    "        -----\n",
    "        categorical_features: tensor, (batch_size, n_channels, screen_res, screen_res)\n",
    "        actions: array, (batch_size,)\n",
    "        \"\"\"\n",
    "        batch_size = actions.shape[0]\n",
    "        parallel_args, parallel_log_prob = self.categorical_params_net(categorical_features)\n",
    "        arg_mask = self.categorical_arg_mask[actions,:] # shape (batch_size, n_spatial_args)\n",
    "        \n",
    "        # select correct arguments\n",
    "        batch_pos = arg_mask.nonzero()[0]\n",
    "        arg_pos = arg_mask.nonzero()[1]\n",
    "        args = parallel_args[batch_pos, arg_pos]\n",
    "        arg_list = [list(args[batch_pos==i]) for i in range(batch_size )]\n",
    "\n",
    "        # select and sum correct log probs\n",
    "        if parallel_log_prob.is_cuda:\n",
    "            device = 'cuda' # Assume only 1 GPU device is used \n",
    "        else:\n",
    "            device = 'cpu'\n",
    "\n",
    "        # for every arg index contains the index of the action that uses that parameter\n",
    "        main_action_ids = torch.tensor(self.categorical_arg_mask.nonzero()[0]).to(device)\n",
    "        if debug:\n",
    "            expected = self.n_categorical_args\n",
    "            actual = main_action_ids.shape[0]\n",
    "            assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "\n",
    "\n",
    "\n",
    "        sum_log_prob = torch.zeros(batch_size, len(self.action_table)) # (batch_size, action_space)\n",
    "        sum_log_prob.index_add_(1, main_action_ids, parallel_log_prob)\n",
    "        sampled_actions = torch.tensor(actions) # of shape (batch_size,)\n",
    "        # sum of log_probs of the relevant parameters by\n",
    "        log_prob = sum_log_prob[torch.arange(batch_size), sampled_actions]\n",
    "        if debug:\n",
    "            expected = batch_size\n",
    "            actual = log_prob.shape[0]\n",
    "            assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                        actual, expected)\n",
    "        return arg_list, log_prob\n",
    "    \n",
    "    def sample_params(self, nonspatial_features, spatial_features, actions):\n",
    "        categorical_arg_list, categorical_log_prob = self.sample_categorical_params(nonspatial_features, actions)\n",
    "        spatial_arg_list, spatial_log_prob = self.sample_spatial_params(spatial_features, actions)\n",
    "        \n",
    "        # merge arg lists\n",
    "        assert len(categorical_arg_list) == len(spatial_arg_list), (\"Expected same length for arg lists\", \\\n",
    "                                                                len(categorical_arg_list), len(spatial_arg_list))\n",
    "        \n",
    "        assert categorical_log_prob.shape == spatial_log_prob.shape, (\"Expected same log_prob shape\", \\\n",
    "                                                                 categorical_log_prob.shape, spatial_log_prob.shape)\n",
    "        log_prob = categorical_log_prob + spatial_log_prob\n",
    "        arg_list = []\n",
    "        for cat, spa in zip(categorical_arg_list, spatial_arg_list):\n",
    "            print(\"cat; \", cat)\n",
    "            print(\"spa: \", spa)\n",
    "            args = []\n",
    "            if len(cat) != 0:\n",
    "                args.append(cat)\n",
    "            args += [list(s) for s in spa] # hopefully is the right format [[arg1],[arg2],...] x batch time\n",
    "            print(\"args: \", args)\n",
    "            arg_list.append(args)\n",
    "            \n",
    "        return arg_list, log_prob\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing everything for real test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment parameters\n",
    "RESOLUTION = 32\n",
    "game_params = dict(feature_screen=RESOLUTION, feature_minimap=RESOLUTION, action_space=\"FEATURES\") \n",
    "game_names = {1:'MoveToBeacon',\n",
    "              2:'CollectMineralShards',\n",
    "              3:'DefeatRoaches',\n",
    "              4:'FindAndDefeatZerglings',\n",
    "              5:'DefeatZerglingsAndBanelings',\n",
    "              6:'CollectMineralsAndGas',\n",
    "              7:'BuildMarines'\n",
    "              }\n",
    "\n",
    "map_name = game_names[1]\n",
    "obs_proc_params = {'select_all':True}\n",
    "# 6 actions, 5 spatial params (select_rect has 2), 5 nonspatial params\n",
    "action_names = ['no_op','select_army','select_rect','Move_screen','select_point','Attack_screen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = init_game(game_params, map_name)\n",
    "op = FullObsProcesser(**obs_proc_params)\n",
    "screen_channels, minimap_channels, in_player = op.get_n_channels()\n",
    "in_channels = screen_channels + minimap_channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_model = net.FullyConvPlayerAndSpatial\n",
    "nonspatial_model = net.FullyConvNonSpatial\n",
    "# Internal features, passed inside a dictionary\n",
    "conv_channels = 32\n",
    "player_features = 16\n",
    "# Exposed features, passed outside of a dictionary\n",
    "n_channels = 48\n",
    "n_features = 256\n",
    "spatial_dict = {\"in_channels\":in_channels, 'in_player':in_player, \n",
    "                'conv_channels':conv_channels, 'player_features':player_features}\n",
    "nonspatial_dict = {'resolution':RESOLUTION, 'kernel_size':3, 'stride':2, 'n_channels':n_channels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "HPs = dict(gamma=0.99, n_steps=20, H=1e-2, \n",
    "           spatial_model=spatial_model, nonspatial_model=nonspatial_model,\n",
    "           n_features=n_features, n_channels=n_channels, action_names=action_names,\n",
    "           spatial_dict=spatial_dict, nonspatial_dict=nonspatial_dict)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    HPs['device'] = 'cuda'\n",
    "else:\n",
    "    HPs['device'] = 'cpu'\n",
    "    \n",
    "print(\"Using device \"+HPs['device'])\n",
    "\n",
    "lr = 7e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSpaceA2C_v2(FullSpaceA2C):\n",
    "    def __init__(self, env, spatial_model, nonspatial_model, spatial_dict, nonspatial_dict, \n",
    "                 n_features, n_channels, action_names, gamma=0.99, H=1e-2, n_steps=20, device='cpu'):\n",
    "        self.gamma = gamma\n",
    "        self.n_steps = n_steps\n",
    "        self.H = H\n",
    "        self.AC = ParallelActorCritic(env, spatial_model, nonspatial_model, spatial_dict, \n",
    "                                     nonspatial_dict, n_features, n_channels, action_names)\n",
    "        self.device = device \n",
    "        self.AC.to(self.device) \n",
    "        \n",
    "    def step(self, state, action_mask):\n",
    "        spatial_state = state['spatial']\n",
    "        player_state = state['player']\n",
    "        spatial_state = torch.from_numpy(spatial_state).float().to(self.device)\n",
    "        player_state = torch.from_numpy(player_state).float().to(self.device)\n",
    "        action_mask = torch.tensor(action_mask).to(self.device)\n",
    "        \n",
    "        log_probs, spatial_features, nonspatial_features = self.AC.pi(spatial_state, player_state, action_mask)\n",
    "        entropy = self.compute_entropy(log_probs)\n",
    "        probs = torch.exp(log_probs)\n",
    "        a = Categorical(probs).sample()\n",
    "        a = a.detach().cpu().numpy()\n",
    "        log_prob = log_probs[range(len(a)), a]\n",
    "        \n",
    "        args, args_log_prob = self.AC.sample_params(nonspatial_features, spatial_features, a)\n",
    "        assert args_log_prob.shape == log_prob.shape, (\"Shape mismatch between arg_log_prob and log_prob \",\\\n",
    "                                                      args_log_prob.shape, log_prob.shape)\n",
    "        log_prob = log_prob + args_log_prob\n",
    "        \n",
    "        action_id = np.array([self.AC.action_table[act] for act in a])\n",
    "        action = [actions.FunctionCall(action_id[i], args[i]) for i in range(len(action_id))]\n",
    "\n",
    "        return action, log_prob, torch.mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FullSpaceA2C_v2(env = env, **HPs)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_processes = 2\n",
    "envs = ParallelEnv(n_train_processes, game_params, map_name, obs_proc_params, agent.AC.action_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, action_mask = envs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat;  []\n",
      "spa:  []\n",
      "args:  []\n",
      "cat;  [0]\n",
      "spa:  [array([10,  5]), array([ 5, 27])]\n",
      "args:  [[0], [10, 5], [5, 27]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[FunctionCall(function=0, arguments=[]),\n",
       " FunctionCall(function=3, arguments=[[0], [10, 5], [5, 27]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, log_prob, entropy = agent.step(state, action_mask)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = envs.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False,  True, False,  True],\n",
       "       [False, False, False,  True, False,  True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_mask # only Move_screen and Attack_screen not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_state = state['spatial']\n",
    "player_state = state['player']\n",
    "spatial_state = torch.from_numpy(spatial_state).float().to(agent.device)\n",
    "player_state = torch.from_numpy(player_state).float().to(agent.device)\n",
    "action_mask = torch.tensor(action_mask).to(agent.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs, spatial_features, nonspatial_features = agent.AC.pi(spatial_state, player_state, action_mask)\n",
    "entropy = agent.compute_entropy(log_probs)\n",
    "probs = torch.exp(log_probs)\n",
    "a = Categorical(probs).sample()\n",
    "a = a.detach().cpu().numpy()\n",
    "log_prob = log_probs[range(len(a)), a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_arg_list, spatial_arg_list = agent.AC.sample_params(nonspatial_features, spatial_features, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([11, 30]), array([ 3, 21])], []]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0], [11, 30], [3, 21]], [[1]]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_list = []\n",
    "for cat, spa in zip(categorical_arg_list, spatial_arg_list):\n",
    "    args = [cat]+[list(s) for s in spa]\n",
    "    arg_list.append(args)\n",
    "arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_id = np.array([agent.AC.action_table[act] for act in a])\n",
    "action_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = [sc_actions.FunctionCall(action_id[i], arg_list[i]) for i in range(len(action_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = envs.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.AC.spatial_params_net.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_args, spatial_log_prob = agent.AC.sample_spatial_params(spatial_features, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1, 23]]), array([[15,  3]])]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.9371, -6.7936], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3695, -1.3670], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob # these 2 can be summed up easily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the same thing for non-spatial params\n",
    "\n",
    "Reference code:\n",
    "```python\n",
    "class CategoricalNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features, size, hiddens=[256]):\n",
    "        super(CategoricalNet, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(nn.Linear(n_features, hiddens[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "            \n",
    "        for i in range(0,len(hiddens)-1):\n",
    "            layers.append(nn.Linear(hiddens[i], hiddens[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Linear(hiddens[-1], size))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, state_rep):\n",
    "        logits = self.net(state_rep)\n",
    "        log_probs = F.log_softmax(logits, dim=(-1))\n",
    "        probs = torch.exp(log_probs)\n",
    "        arg = Categorical(probs).sample()\n",
    "        arg = arg.detach().cpu().numpy()\n",
    "        return arg.reshape(-1,1), log_probs[range(len(arg)), arg], log_probs\n",
    "```\n",
    "\n",
    "Changes:\n",
    "- receive an array of sizes\n",
    "- consider the max size and get the logits of shape (batch_size, n_arguments, sizes)\n",
    "- make a mask of shape (n_arguments, sizes) and repeat it along batch_size\n",
    "    to use like logits.masked_fill(mask.bool(), float('-inf')) before the softmax\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = agent.AC.categorical_sizes\n",
    "categorical_params_net = ParallelCategoricalNet(256, sizes, agent.AC.n_categorical_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 2, 0]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_args, parallel_log_prob = categorical_params_net(nonspatial_features)\n",
    "parallel_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_mask = agent.AC.categorical_arg_mask[a,:] # shape (batch_size, n_spatial_args)\n",
    "if debug:\n",
    "    expected = a.shape + (agent.AC.n_categorical_args,)\n",
    "    actual = arg_mask.shape\n",
    "    assert actual == expected, (\"unexpected arg_mask shape; actual vs expected: \", \\\n",
    "                                actual, expected)\n",
    "\n",
    "arg_mask      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = arg_mask.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pos:  [0 1]\n",
      "arg_pos:  [3 3]\n",
      "args:  [0 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0], [2]]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select correct action\n",
    "batch_pos = arg_mask.nonzero()[0]\n",
    "print(\"batch_pos: \", batch_pos)\n",
    "arg_pos = arg_mask.nonzero()[1]\n",
    "print(\"arg_pos: \", arg_pos)\n",
    "args = parallel_args[batch_pos, arg_pos]\n",
    "print(\"args: \", args)\n",
    "arg_list = [list(args[batch_pos==i]) for i in range(batch_size )]\n",
    "arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7394, -0.7430, -0.7037, -1.3580, -0.7493],\n",
       "        [-0.7369, -0.7440, -0.7031, -1.3919, -0.7464]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select and sum correct log probs\n",
    "\n",
    "if parallel_log_prob.is_cuda:\n",
    "    device = 'cuda' # Assume only 1 GPU device is used \n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "# for every arg index contains the index of the action that uses that parameter\n",
    "main_action_ids = torch.tensor(agent.AC.categorical_arg_mask.nonzero()[0]).to(device)\n",
    "if debug:\n",
    "    expected = agent.AC.n_categorical_args\n",
    "    actual = main_action_ids.shape[0]\n",
    "    assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                actual, expected)\n",
    "\n",
    "\n",
    "            \n",
    "sum_log_prob = torch.zeros(batch_size, len(agent.AC.action_table)) # (batch_size, action_space)\n",
    "sum_log_prob.index_add_(1, main_action_ids, parallel_log_prob)\n",
    "sampled_actions = torch.tensor(a) # of shape (batch_size,)\n",
    "# sum of log_probs of the relevant parameters by\n",
    "log_prob = sum_log_prob[torch.arange(batch_size), sampled_actions]\n",
    "if debug:\n",
    "    expected = batch_size\n",
    "    actual = log_prob.shape[0]\n",
    "    assert actual == expected, (\"unexpected main_action_ids shape; actual vs expected: \", \\\n",
    "                                actual, expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3580, -1.3919], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ced5f7c27bc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_log_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspatial_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonspatial_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs_log_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Use only entropy of main actions for regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#entropy = entropy + args_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "args, args_log_prob, args_entropy = self.get_arguments(spatial_features, nonspatial_features, a)\n",
    "log_prob = log_prob + args_log_prob\n",
    "# Use only entropy of main actions for regularization\n",
    "#entropy = entropy + args_entropy\n",
    "\n",
    "action_id = np.array([self.AC.action_dict[act] for act in a])\n",
    "action = [actions.FunctionCall(action_id[i], args[i]) for i in range(len(action_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actions = env.action_spec()[0][1]\n",
    "all_arguments = env.action_spec()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_table(action_names):\n",
    "    action_ids = [sc_actions.FUNCTIONS[a_name].id for a_name in action_names]\n",
    "    action_table = np.array([action_ids[i] for i in range(len(action_ids))])\n",
    "    return action_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   7,   3, 331,   2,  12])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_names = ['no_op','select_army','select_rect','Move_screen','select_point','Attack_screen']\n",
    "action_table = get_action_table(action_names) \n",
    "action_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial_arg_names:  ['select_rect/screen', 'select_rect/screen2', 'Move_screen/screen', 'select_point/screen', 'Attack_screen/screen']\n",
      "Number of args:  5\n",
      "categorical_arg_names:  ['select_army/select_add', 'select_rect/select_add', 'Move_screen/queued', 'select_point/select_point_act', 'Attack_screen/queued']\n",
      "Number of args:  5\n"
     ]
    }
   ],
   "source": [
    "# now we need to get all the possible arguments counted twice if they belong to different actions\n",
    "def _init_arg_names(action_table):\n",
    "    \"\"\"\n",
    "    Add self as first argument and use it as a class method in the AC.\n",
    "    Assume all_actions and all_arguments as attributes of the class (add self. in front of them)\n",
    "    Also instead of returning the results, add them as attributes of the class.\n",
    "    \"\"\"\n",
    "    spatial_arg_names = []\n",
    "    categorical_arg_names = []\n",
    "    categorical_sizes = []\n",
    "    act_to_arg_names = {}\n",
    "\n",
    "    for action_id in action_table:\n",
    "        action = all_actions[action_id]\n",
    "        args = action.args\n",
    "        act_to_arg_names[action_id] = [str(action.name)+\"/\"+arg.name for arg in args]\n",
    "        spatial = []\n",
    "        categorical = []\n",
    "        for arg in args:\n",
    "            arg_name = str(action.name)+\"/\"+arg.name\n",
    "            size = all_arguments[arg.id].sizes\n",
    "            if len(size) == 1:\n",
    "                categorical.append(arg_name)\n",
    "                categorical_sizes.append(size)\n",
    "            else:\n",
    "                spatial.append(arg_name)\n",
    "        spatial_arg_names+=spatial\n",
    "        categorical_arg_names+=categorical\n",
    "    return spatial_arg_names, categorical_arg_names, act_to_arg_names\n",
    "\n",
    "spatial_arg_names, categorical_arg_names, act_to_arg_names = _init_arg_names(action_table)\n",
    "        \n",
    "print('spatial_arg_names: ', spatial_arg_names)\n",
    "print(\"Number of args: \", len(spatial_arg_names))\n",
    "print('categorical_arg_names: ', categorical_arg_names)\n",
    "print(\"Number of args: \", len(categorical_arg_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spatial_arg_mask(action_table, spatial_arg_names):\n",
    "    spatial_arg_mask = np.zeros((action_table.shape[0], len(spatial_arg_names)))\n",
    "    for i, action_id in enumerate(action_table):\n",
    "        action_arg_names = act_to_arg_names[action_id]\n",
    "        spatial_arg_mask[i] = np.array([1 if spatial_arg_names[j] in action_arg_names else 0 for j in range(len(spatial_arg_names))])\n",
    "    return spatial_arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_arg_mask = get_spatial_arg_mask(action_table, spatial_arg_names)\n",
    "spatial_arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_arg_mask(action_table, categorical_arg_names):\n",
    "    categorical_arg_mask = np.zeros((action_table.shape[0], len(categorical_arg_names)))\n",
    "    for i, action_id in enumerate(action_table):\n",
    "        action_arg_names = act_to_arg_names[action_id]\n",
    "        categorical_arg_mask[i] = np.array([1 if categorical_arg_names[j] in action_arg_names else 0 for j in range(len(categorical_arg_names))])\n",
    "    return categorical_arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_arg_mask = get_categorical_arg_mask(action_table, categorical_arg_names)\n",
    "categorical_arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.array([2,1,0])\n",
    "spatial_arg_mask[actions,:] # use this to access args or mask log probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 32, 32])\n",
      "args:  (3, 5, 2) \n",
      " [[[14 16]\n",
      "  [13 25]\n",
      "  [ 6 25]\n",
      "  [28  4]\n",
      "  [ 3 20]]\n",
      "\n",
      " [[13 12]\n",
      "  [16 11]\n",
      "  [ 9 18]\n",
      "  [20 29]\n",
      "  [11 15]]\n",
      "\n",
      " [[15 18]\n",
      "  [11 20]\n",
      "  [ 5 21]\n",
      "  [18 28]\n",
      "  [ 7  9]]]\n",
      "log_prob:  tensor([[-6.7258, -6.9170, -7.1031, -7.2827, -7.0330],\n",
      "        [-6.7674, -7.1977, -6.7109, -6.7441, -6.9934],\n",
      "        [-6.9490, -6.9059, -6.5702, -6.8146, -7.0296]], grad_fn=<ViewBackward>)\n",
      "log_probs.shape:  torch.Size([3, 5, 1024])\n"
     ]
    }
   ],
   "source": [
    "B = 3\n",
    "n_channels = 16\n",
    "res = 32\n",
    "n_arguments = 5\n",
    "x = torch.rand(B,n_channels,res,res)\n",
    "print(x.shape)\n",
    "spatial_net = ParallelSpatialParameters(n_channels, res, n_arguments)\n",
    "args, log_prob, log_probs = spatial_net(x) # I can forget about log_probs, because I don't compute their entropy\n",
    "print('args: ', args.shape, '\\n', args) # lipst of lists\n",
    "print('log_prob: ', log_prob)\n",
    "print('log_probs.shape: ', log_probs.shape) # (B, res**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.array([2,1,3])\n",
    "arg_mask = spatial_arg_mask[actions,:] # use this to access args or mask log probs\n",
    "arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pos = arg_mask.nonzero()[0]\n",
    "batch_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_pos = arg_mask.nonzero()[1]\n",
    "arg_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 16],\n",
       "       [ 9, 15],\n",
       "       [21,  3]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_selected = args[batch_pos, arg_pos]\n",
    "args_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 7, 16],\n",
       "        [ 9, 15]]), array([], shape=(0, 2), dtype=int64), array([[21,  3]])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of them based on batch_pos\n",
    "arg_list = [args_selected[batch_pos==i] for i in range(B)]\n",
    "arg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [1., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_arg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_action_ids = torch.tensor(spatial_arg_mask.nonzero()[0])\n",
    "main_action_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000, -14.0128,  -7.1679,  -6.9187,  -7.1077],\n",
       "        [  0.0000,   0.0000, -14.0146,  -6.6906,  -7.0085,  -6.6435],\n",
       "        [  0.0000,   0.0000, -13.7723,  -6.5021,  -6.9189,  -6.6367]],\n",
       "       grad_fn=<IndexAddBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actions = len(action_table)\n",
    "sum_log_prob = torch.zeros(B, n_actions)\n",
    "sum_log_prob.index_add_(1, main_action_ids, log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-14.0128,   0.0000,  -6.5021], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if you sample actions\n",
    "samples = torch.tensor(actions) # of shape (batch_size,)\n",
    "# you can get the sum of log_probs of the relevant parameters by\n",
    "sum_log_prob[torch.arange(B), samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexander code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9e13e84391e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#which positions are owned by which argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain_action_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mn_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_action_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;31m# all possible unique elements in main_action_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#which positions are owned by which argument\n",
    "main_action_ids = torch.tensor([0, 0, 1, 1, 2])\n",
    "n_arguments = len(main_action_ids)\n",
    "n_actions = 3 # all possible unique elements in main_action_ids\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = torch.arange(batch_size*n_arguments).float().view(batch_size, n_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.1397, -7.0619, -6.8159,  ..., -6.9571, -6.8822, -6.6614],\n",
       "         [-7.2100, -6.8245, -6.8680,  ..., -7.1253, -7.2476, -6.8876],\n",
       "         [-6.7696, -7.1995, -6.9974,  ..., -6.8698, -6.7482, -6.2425],\n",
       "         [-6.5937, -6.6011, -6.9123,  ..., -6.9024, -7.0177, -6.8117],\n",
       "         [-6.7422, -6.7434, -6.5691,  ..., -7.0115, -7.1403, -7.3158]],\n",
       "\n",
       "        [[-6.9153, -6.7841, -6.7303,  ..., -6.9872, -6.8430, -6.7925],\n",
       "         [-6.9692, -6.6834, -7.1690,  ..., -6.9372, -7.2004, -6.9948],\n",
       "         [-6.7372, -7.2126, -7.0391,  ..., -6.6308, -6.5861, -6.3031],\n",
       "         [-6.7129, -6.7453, -6.8583,  ..., -6.9967, -7.1100, -6.7289],\n",
       "         [-6.8226, -6.8818, -6.7086,  ..., -7.1040, -6.8994, -7.3203]],\n",
       "\n",
       "        [[-7.0819, -6.9388, -7.0197,  ..., -6.8330, -6.8524, -7.0321],\n",
       "         [-6.9040, -6.7202, -7.0060,  ..., -7.0316, -7.0382, -6.7653],\n",
       "         [-6.7028, -6.9682, -6.9849,  ..., -6.4215, -6.4388, -6.1832],\n",
       "         [-6.6856, -6.8304, -6.7160,  ..., -7.1000, -7.0478, -6.8546],\n",
       "         [-6.7928, -6.5417, -6.7195,  ..., -7.4844, -7.2196, -7.0488]]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  5.,  4.],\n",
       "        [11., 15.,  9.],\n",
       "        [21., 25., 14.],\n",
       "        [31., 35., 19.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_log_probs = torch.zeros(batch_size, n_actions)\n",
    "sum_log_probs.index_add_(1, main_action_ids, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1., 15., 21., 19.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if you sample actions\n",
    "samples = torch.tensor([0, 1, 0, 2]) # of shape (batch_size,)\n",
    "# you can get the sum of log_probs of the relevant parameters by\n",
    "sum_log_probs[torch.arange(batch_size), samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other part\n",
    "\n",
    "Values are all the possible values that each argument can assume; n_values in reality would be res**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "n_values = 6 # possible range of sample_value_ids\n",
    "log_probs = torch.arange(batch_size*n_arguments*n_values).float().view(batch_size, n_arguments, n_values)\n",
    "\n",
    "# We sample based on these log_probs\n",
    "sample_value_ids = torch.tensor([\n",
    "    [0, 0, 1, 1, 2],\n",
    "    [3, 3, 4, 4, 5],\n",
    "    [0, 1, 2, 3, 4],\n",
    "    [5, 4, 3, 2, 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   1.,   2.,   3.,   4.,   5.],\n",
       "         [  6.,   7.,   8.,   9.,  10.,  11.],\n",
       "         [ 12.,  13.,  14.,  15.,  16.,  17.],\n",
       "         [ 18.,  19.,  20.,  21.,  22.,  23.],\n",
       "         [ 24.,  25.,  26.,  27.,  28.,  29.]],\n",
       "\n",
       "        [[ 30.,  31.,  32.,  33.,  34.,  35.],\n",
       "         [ 36.,  37.,  38.,  39.,  40.,  41.],\n",
       "         [ 42.,  43.,  44.,  45.,  46.,  47.],\n",
       "         [ 48.,  49.,  50.,  51.,  52.,  53.],\n",
       "         [ 54.,  55.,  56.,  57.,  58.,  59.]],\n",
       "\n",
       "        [[ 60.,  61.,  62.,  63.,  64.,  65.],\n",
       "         [ 66.,  67.,  68.,  69.,  70.,  71.],\n",
       "         [ 72.,  73.,  74.,  75.,  76.,  77.],\n",
       "         [ 78.,  79.,  80.,  81.,  82.,  83.],\n",
       "         [ 84.,  85.,  86.,  87.,  88.,  89.]],\n",
       "\n",
       "        [[ 90.,  91.,  92.,  93.,  94.,  95.],\n",
       "         [ 96.,  97.,  98.,  99., 100., 101.],\n",
       "         [102., 103., 104., 105., 106., 107.],\n",
       "         [108., 109., 110., 111., 112., 113.],\n",
       "         [114., 115., 116., 117., 118., 119.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_log_probs = log_probs.view(batch_size*n_arguments, n_values) \\\n",
    "[torch.arange(batch_size*n_arguments), sample_value_ids.flatten()] \\\n",
    ".view(batch_size, n_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   6.,  13.,  19.,  26.],\n",
       "        [ 33.,  39.,  46.,  52.,  59.],\n",
       "        [ 60.,  67.,  74.,  81.,  88.],\n",
       "        [ 95., 100., 105., 110., 115.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
